{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLGbz6Kw_3Jd",
        "outputId": "d557e7e8-d743-402c-9045-2649d0974d47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import shutil\n",
        "\n",
        "# source_folder = '/content/drive/MyDrive/cyclegans/preprocess'\n",
        "# destination_folder = '/content/drive/MyDrive/cyclegans_new/preprocess'\n",
        "\n",
        "# shutil.copytree(source_folder, destination_folder)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-EVLspJl_-wS",
        "outputId": "1a09c058-f88a-4115-9373-ab031e6d81a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/cyclegans_new/preprocess'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !mkdir -p '/content/drive/MyDrive/cyclegans_new/preprocess'"
      ],
      "metadata": {
        "id": "cAGLn3HmAuNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -r /content/drive/MyDrive/cyclegans_new\n"
      ],
      "metadata": {
        "id": "QxgobkhUA6v9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Change this path to where you want your project to live in Google Drive\n",
        "# %cd /content/drive/MyDrive/cyclegans_new\n",
        "\n",
        "# # Clone the repo and install dependencies\n",
        "# !git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix.git\n",
        "# %cd pytorch-CycleGAN-and-pix2pix/\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "7YjU_t2kBGNr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c85a03e-e62c-4303-8fb1-0b065afd0e25"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (0.21.0+cu124)\n",
            "Collecting dominate>=2.4.0 (from -r requirements.txt (line 3))\n",
            "  Downloading dominate-2.9.1-py2.py3-none-any.whl.metadata (13 kB)\n",
            "Collecting visdom>=0.1.8.8 (from -r requirements.txt (line 4))\n",
            "  Downloading visdom-0.2.4.tar.gz (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (0.21.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (2025.7.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.4.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.4.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.4.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.4.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.4.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.4.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.4.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.4.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.4.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.4.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.4.0->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (11.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.16.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (2.32.3)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.11/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (6.4.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.17.0)\n",
            "Requirement already satisfied: jsonpatch in /usr/local/lib/python3.11/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.33)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.8.0)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (8.2.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (3.1.44)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (25.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (4.3.8)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (2.11.7)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (6.0.2)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (2.33.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 5)) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb->-r requirements.txt (line 5)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb->-r requirements.txt (line 5)) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb->-r requirements.txt (line 5)) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (2025.7.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.4.0->-r requirements.txt (line 1)) (3.0.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch->visdom>=0.1.8.8->-r requirements.txt (line 4)) (3.0.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 5)) (5.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m108.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dominate-2.9.1-py2.py3-none-any.whl (29 kB)\n",
            "Building wheels for collected packages: visdom\n",
            "  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for visdom: filename=visdom-0.2.4-py3-none-any.whl size=1408195 sha256=1662589fd04708e7483793ead577ef183919277f42ad6a4978ef74128e244887\n",
            "  Stored in directory: /root/.cache/pip/wheels/fa/a4/bb/2be445c295d88a74f9c0a4232f04860ca489a5c7c57eb959d9\n",
            "Successfully built visdom\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, dominate, visdom, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed dominate-2.9.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 visdom-0.2.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/cyclegans_new/pytorch-CycleGAN-and-pix2pix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bS2aBEtcWpWf",
        "outputId": "430a6e08-64b6-4e1b-ea34-b45f6a32764f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/cyclegans_new/pytorch-CycleGAN-and-pix2pix\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PERCEPTUAL LOSS\n",
        "To improve the visual quality of the generated images, we supplement the standard L1 cycle-consistency loss with a Perceptual Loss (also known as VGG Loss). While L1 loss is effective at preserving the overall structure, it often encourages overly smooth or blurry results by averaging pixel values. The Perceptual Loss addresses this by comparing high-level features (like textures and edges) instead of raw pixels. It uses a pre-trained VGG19 network as an expert feature extractor. By minimizing the difference between the feature maps of the generated and target images, the model is encouraged to produce significantly sharper and more realistic details that better align with human perception."
      ],
      "metadata": {
        "id": "p4gZ_CnsqpBQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the existing networks.py file\n",
        "with open('models/networks.py', 'r') as f:\n",
        "    original_content = f.read()\n",
        "\n",
        "# Define the new VGGPerceptualLoss class\n",
        "perceptual_loss_code = \"\"\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "class VGGPerceptualLoss(nn.Module):\n",
        "    def __init__(self, resize=True):\n",
        "        super(VGGPerceptualLoss, self).__init__()\n",
        "        blocks = []\n",
        "        blocks.append(models.vgg19(pretrained=True).features[:4].eval())\n",
        "        blocks.append(models.vgg19(pretrained=True).features[4:9].eval())\n",
        "        blocks.append(models.vgg19(pretrained=True).features[9:18].eval())\n",
        "        blocks.append(models.vgg19(pretrained=True).features[18:27].eval())\n",
        "        for bl in blocks:\n",
        "            for p in bl.parameters():\n",
        "                p.requires_grad = False\n",
        "        self.blocks = nn.ModuleList(blocks)\n",
        "        self.transform = nn.functional.interpolate\n",
        "        self.resize = resize\n",
        "        self.register_buffer(\"mean\", torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1))\n",
        "        self.register_buffer(\"std\", torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1))\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        # VGG expects 3 channels. If input is grayscale, repeat the channel.\n",
        "        if input.shape[1] != 3:\n",
        "            input = input.repeat(1, 3, 1, 1)\n",
        "            target = target.repeat(1, 3, 1, 1)\n",
        "        # De-normalize from [-1, 1] to [0, 1]\n",
        "        input = (input + 1) / 2\n",
        "        target = (target + 1) / 2\n",
        "        # Normalize for VGG\n",
        "        input = (input - self.mean) / self.std\n",
        "        target = (target - self.mean) / self.std\n",
        "        if self.resize:\n",
        "            input = self.transform(input, mode='bilinear', size=(224, 224), align_corners=False)\n",
        "            target = self.transform(target, mode='bilinear', size=(224, 224), align_corners=False)\n",
        "        loss = 0.0\n",
        "        x = input\n",
        "        y = target\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "            y = block(y)\n",
        "            loss += nn.functional.l1_loss(x, y)\n",
        "        return loss\n",
        "\"\"\"\n",
        "\n",
        "# Append the new class to the original content and overwrite the file\n",
        "with open('models/networks.py', 'w') as f:\n",
        "    f.write(original_content + \"\\n\" + perceptual_loss_code)\n",
        "\n",
        "print(\"✅ Appended VGGPerceptualLoss to models/networks.py\")\n",
        "print(\"Note: The first time you train, PyTorch will download the VGG19 model weights.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eTLh69tb9JN",
        "outputId": "27a6ca29-96fa-4a32-8b94-56e56800920a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Appended VGGPerceptualLoss to models/networks.py\n",
            "Note: The first time you train, PyTorch will download the VGG19 model weights.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile models/cycle_gan_model.py\n",
        "import torch\n",
        "import itertools\n",
        "from util.image_pool import ImagePool\n",
        "from .base_model import BaseModel\n",
        "from . import networks\n",
        "\n",
        "\n",
        "class CycleGANModel(BaseModel):\n",
        "    @staticmethod\n",
        "    def modify_commandline_options(parser, is_train=True):\n",
        "        parser.set_defaults(no_dropout=True)\n",
        "        if is_train:\n",
        "            parser.add_argument('--lambda_A', type=float, default=10.0, help='weight for cycle loss (A -> B -> A)')\n",
        "            parser.add_argument('--lambda_B', type=float, default=10.0, help='weight for cycle loss (B -> A -> B)')\n",
        "            parser.add_argument('--lambda_identity', type=float, default=0.5, help='use identity mapping.')\n",
        "            # Add a new flag for our perceptual loss\n",
        "            parser.add_argument('--lambda_perceptual', type=float, default=1.0, help='weight for perceptual loss')\n",
        "        return parser\n",
        "\n",
        "    def __init__(self, opt):\n",
        "        BaseModel.__init__(self, opt)\n",
        "        # Add 'perceptual' to the list of losses to log\n",
        "        self.loss_names = ['D_A', 'G_A', 'cycle_A', 'idt_A', 'D_B', 'G_B', 'cycle_B', 'idt_B', 'perceptual']\n",
        "        visual_names_A = ['real_A', 'fake_B', 'rec_A']\n",
        "        visual_names_B = ['real_B', 'fake_A', 'rec_B']\n",
        "        self.visual_names = visual_names_A + visual_names_B\n",
        "        self.model_names = ['G_A', 'G_B', 'D_A', 'D_B']\n",
        "        self.netG_A = networks.define_G(opt.input_nc, opt.output_nc, opt.ngf, opt.netG, opt.norm,\n",
        "                                        not opt.no_dropout, opt.init_type, opt.init_gain, self.gpu_ids)\n",
        "        self.netG_B = networks.define_G(opt.output_nc, opt.input_nc, opt.ngf, opt.netG, opt.norm,\n",
        "                                        not opt.no_dropout, opt.init_type, opt.init_gain, self.gpu_ids)\n",
        "\n",
        "        if self.isTrain:\n",
        "            self.netD_A = networks.define_D(opt.output_nc, opt.ndf, opt.netD,\n",
        "                                            opt.n_layers_D, opt.norm, opt.init_type, opt.init_gain, self.gpu_ids)\n",
        "            self.netD_B = networks.define_D(opt.input_nc, opt.ndf, opt.netD,\n",
        "                                            opt.n_layers_D, opt.norm, opt.init_type, opt.init_gain, self.gpu_ids)\n",
        "            self.fake_A_pool = ImagePool(opt.pool_size)\n",
        "            self.fake_B_pool = ImagePool(opt.pool_size)\n",
        "            # define loss functions\n",
        "            self.criterionGAN = networks.GANLoss(opt.gan_mode).to(self.device)\n",
        "            self.criterionCycle = torch.nn.L1Loss()\n",
        "            self.criterionIdt = torch.nn.L1Loss()\n",
        "            # Initialize the perceptual loss\n",
        "            self.criterionPerceptual = networks.VGGPerceptualLoss().to(self.device)\n",
        "            # initialize optimizers\n",
        "            self.optimizer_G = torch.optim.Adam(itertools.chain(self.netG_A.parameters(), self.netG_B.parameters()), lr=opt.lr, betas=(opt.beta1, 0.999))\n",
        "            self.optimizer_D = torch.optim.Adam(itertools.chain(self.netD_A.parameters(), self.netD_B.parameters()), lr=opt.lr, betas=(opt.beta1, 0.999))\n",
        "            self.optimizers.append(self.optimizer_G)\n",
        "            self.optimizers.append(self.optimizer_D)\n",
        "\n",
        "    def set_input(self, input):\n",
        "        AtoB = self.opt.direction == 'AtoB'\n",
        "        self.real_A = input['A' if AtoB else 'B'].to(self.device)\n",
        "        self.real_B = input['B' if AtoB else 'A'].to(self.device)\n",
        "        self.image_paths = input['A_paths' if AtoB else 'B_paths']\n",
        "\n",
        "    def forward(self):\n",
        "        \"\"\"Run forward pass\"\"\"\n",
        "        self.fake_B = self.netG_A(self.real_A)\n",
        "        self.rec_A = self.netG_B(self.fake_B)\n",
        "        self.fake_A = self.netG_B(self.real_B)\n",
        "        self.rec_B = self.netG_A(self.fake_A)\n",
        "\n",
        "    def backward_D_basic(self, netD, real, fake):\n",
        "        pred_real = netD(real)\n",
        "        loss_D_real = self.criterionGAN(pred_real, True)\n",
        "        pred_fake = netD(fake.detach())\n",
        "        loss_D_fake = self.criterionGAN(pred_fake, False)\n",
        "        loss_D = (loss_D_real + loss_D_fake) * 0.5\n",
        "        loss_D.backward()\n",
        "        return loss_D\n",
        "\n",
        "    def backward_D_A(self):\n",
        "        fake_B = self.fake_B_pool.query(self.fake_B)\n",
        "        self.loss_D_A = self.backward_D_basic(self.netD_A, self.real_B, fake_B)\n",
        "\n",
        "    def backward_D_B(self):\n",
        "        fake_A = self.fake_A_pool.query(self.fake_A)\n",
        "        self.loss_D_B = self.backward_D_basic(self.netD_B, self.real_A, fake_A)\n",
        "\n",
        "    def backward_G(self):\n",
        "        lambda_idt = self.opt.lambda_identity\n",
        "        lambda_A = self.opt.lambda_A\n",
        "        lambda_B = self.opt.lambda_B\n",
        "        lambda_perceptual = self.opt.lambda_perceptual\n",
        "\n",
        "        # Identity loss\n",
        "        self.loss_idt_A = 0\n",
        "        self.loss_idt_B = 0\n",
        "        if lambda_idt > 0:\n",
        "            self.idt_A = self.netG_A(self.real_B)\n",
        "            self.loss_idt_A = self.criterionIdt(self.idt_A, self.real_B) * lambda_B * lambda_idt\n",
        "            self.idt_B = self.netG_B(self.real_A)\n",
        "            self.loss_idt_B = self.criterionIdt(self.idt_B, self.real_A) * lambda_A * lambda_idt\n",
        "\n",
        "        # GAN loss\n",
        "        self.loss_G_A = self.criterionGAN(self.netD_A(self.fake_B), True)\n",
        "        self.loss_G_B = self.criterionGAN(self.netD_B(self.fake_A), True)\n",
        "        # Cycle loss\n",
        "        self.loss_cycle_A = self.criterionCycle(self.rec_A, self.real_A) * lambda_A\n",
        "        self.loss_cycle_B = self.criterionCycle(self.rec_B, self.real_B) * lambda_B\n",
        "\n",
        "        # --- NEW: Perceptual Loss Calculation ---\n",
        "        # Compare real and reconstructed images in both directions\n",
        "        self.loss_perceptual_A = self.criterionPerceptual(self.rec_A, self.real_A) * lambda_A * lambda_perceptual\n",
        "        self.loss_perceptual_B = self.criterionPerceptual(self.rec_B, self.real_B) * lambda_B * lambda_perceptual\n",
        "        self.loss_perceptual = self.loss_perceptual_A + self.loss_perceptual_B\n",
        "        # --- END NEW ---\n",
        "\n",
        "        # Combine all losses and calculate gradients\n",
        "        self.loss_G = (self.loss_G_A + self.loss_G_B + self.loss_cycle_A + self.loss_cycle_B +\n",
        "                       self.loss_idt_A + self.loss_idt_B + self.loss_perceptual)\n",
        "        self.loss_G.backward()\n",
        "\n",
        "    def optimize_parameters(self):\n",
        "        self.forward()\n",
        "        self.set_requires_grad([self.netD_A, self.netD_B], False)\n",
        "        self.optimizer_G.zero_grad()\n",
        "        self.backward_G()\n",
        "        self.optimizer_G.step()\n",
        "        self.set_requires_grad([self.netD_A, self.netD_B], True)\n",
        "        self.optimizer_D.zero_grad()\n",
        "        self.backward_D_A()\n",
        "        self.backward_D_B()\n",
        "        self.optimizer_D.step()\n",
        "\n",
        "print(\"✅ Patched cycle_gan_model.py with Perceptual Loss.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7PJpus7cyb0",
        "outputId": "0690985c-4799-43cd-bf70-075b0140dfdb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting models/cycle_gan_model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Custom Dataloaders"
      ],
      "metadata": {
        "id": "wdTnPQIlBpcB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile data/unaligned_npy_dataset.py\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from data.base_dataset import BaseDataset\n",
        "\n",
        "class UnalignedNpyDataset(BaseDataset):\n",
        "    \"\"\"This dataset class can load unaligned/unpaired datasets of .npy files.\"\"\"\n",
        "    def __init__(self, opt):\n",
        "        BaseDataset.__init__(self, opt)\n",
        "        self.dir_A = os.path.join(opt.dataroot, 'trainA')\n",
        "        self.dir_B = os.path.join(opt.dataroot, 'trainB')\n",
        "\n",
        "        self.A_paths = sorted([os.path.join(self.dir_A, f) for f in os.listdir(self.dir_A) if f.endswith('.npy')])\n",
        "        self.B_paths = sorted([os.path.join(self.dir_B, f) for f in os.listdir(self.dir_B) if f.endswith('.npy')])\n",
        "        self.A_size = len(self.A_paths)\n",
        "        self.B_size = len(self.B_paths)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        A_path = self.A_paths[index % self.A_size]\n",
        "        index_B = np.random.randint(0, self.B_size - 1)\n",
        "        B_path = self.B_paths[index_B]\n",
        "\n",
        "        A_npy = np.load(A_path).astype(np.float32)\n",
        "        B_npy = np.load(B_path).astype(np.float32)\n",
        "\n",
        "        A_tensor = torch.from_numpy(A_npy.transpose((2, 0, 1)))\n",
        "        B_tensor = torch.from_numpy(B_npy.transpose((2, 0, 1)))\n",
        "\n",
        "        return {'A': A_tensor, 'B': B_tensor, 'A_paths': A_path, 'B_paths': B_path}\n",
        "\n",
        "    def __len__(self):\n",
        "        return max(self.A_size, self.B_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OImWg1uHdTaT",
        "outputId": "7fc081c9-5583-4649-d907-760161449b6f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting data/unaligned_npy_dataset.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Read the existing networks.py file\n",
        "with open('models/networks.py', 'r') as f:\n",
        "    original_content = f.read()\n",
        "\n",
        "# Remove the old, buggy VGGPerceptualLoss class definition if it exists\n",
        "# This makes the script safe to run multiple times\n",
        "cleaned_content = re.sub(r'class VGGPerceptualLoss.*', '', original_content, flags=re.DOTALL)\n",
        "\n",
        "# Define the new, corrected VGGPerceptualLoss class\n",
        "corrected_perceptual_loss_code = \"\"\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "class VGGPerceptualLoss(nn.Module):\n",
        "    def __init__(self, resize=True):\n",
        "        super(VGGPerceptualLoss, self).__init__()\n",
        "        blocks = []\n",
        "        blocks.append(models.vgg19(pretrained=True).features[:4].eval())\n",
        "        blocks.append(models.vgg19(pretrained=True).features[4:9].eval())\n",
        "        blocks.append(models.vgg19(pretrained=True).features[9:18].eval())\n",
        "        blocks.append(models.vgg19(pretrained=True).features[18:27].eval())\n",
        "        for bl in blocks:\n",
        "            for p in bl.parameters():\n",
        "                p.requires_grad = False\n",
        "        self.blocks = nn.ModuleList(blocks)\n",
        "        self.transform = nn.functional.interpolate\n",
        "        self.resize = resize\n",
        "        self.register_buffer(\"mean\", torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1))\n",
        "        self.register_buffer(\"std\", torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1))\n",
        "\n",
        "    def forward(self, input, target, feature_layers=[0, 1, 2, 3], style_layers=[]):\n",
        "        # --- START OF FIX ---\n",
        "        # Handle inputs with different channel numbers correctly\n",
        "        if input.shape[1] == 1: # Grayscale\n",
        "            input = input.repeat(1, 3, 1, 1)\n",
        "            target = target.repeat(1, 3, 1, 1)\n",
        "        elif input.shape[1] == 2: # 2-Channel SAR Data\n",
        "            # Use the first channel (e.g., VV) and repeat it to create a 3-channel grayscale image\n",
        "            input = input[:, 0:1, :, :].repeat(1, 3, 1, 1)\n",
        "            target = target[:, 0:1, :, :].repeat(1, 3, 1, 1)\n",
        "        # --- END OF FIX ---\n",
        "\n",
        "        # De-normalize from [-1, 1] to [0, 1]\n",
        "        input = (input + 1) / 2\n",
        "        target = (target + 1) / 2\n",
        "        # Normalize for VGG\n",
        "        input = (input - self.mean) / self.std\n",
        "        target = (target - self.mean) / self.std\n",
        "        if self.resize:\n",
        "            input = self.transform(input, mode='bilinear', size=(224, 224), align_corners=False)\n",
        "            target = self.transform(target, mode='bilinear', size=(224, 224), align_corners=False)\n",
        "        loss = 0.0\n",
        "        x = input\n",
        "        y = target\n",
        "        for i, block in enumerate(self.blocks):\n",
        "            x = block(x)\n",
        "            y = block(y)\n",
        "            if i in feature_layers:\n",
        "                loss += nn.functional.l1_loss(x, y)\n",
        "        return loss\n",
        "\"\"\"\n",
        "\n",
        "# Append the new class to the cleaned content and overwrite the file\n",
        "with open('models/networks.py', 'w') as f:\n",
        "    f.write(cleaned_content + \"\\n\" + corrected_perceptual_loss_code)\n",
        "\n",
        "print(\"✅ Corrected the VGGPerceptualLoss class in models/networks.py\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUkgyyjndxH8",
        "outputId": "b12174a2-4d1f-4745-d723-3ce1a1944dad"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Corrected the VGGPerceptualLoss class in models/networks.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile util/util.py\n",
        "\"\"\"This module contains simple helper functions \"\"\"\n",
        "from __future__ import print_function\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "\n",
        "def tensor2im(input_image, imtype=np.uint8):\n",
        "    \"\"\"\"Converts a Tensor array into a numpy image array.\"\"\"\n",
        "    if not isinstance(input_image, np.ndarray):\n",
        "        if isinstance(input_image, torch.Tensor):\n",
        "            image_tensor = input_image.data\n",
        "        else:\n",
        "            return input_image\n",
        "        image_numpy = image_tensor[0].cpu().float().numpy()\n",
        "\n",
        "        # --- START OF FIX ---\n",
        "        # Handle inputs with different channel numbers correctly for visualization\n",
        "        if image_numpy.ndim == 2:  # Handle 2D arrays\n",
        "            image_numpy = np.expand_dims(image_numpy, axis=0)\n",
        "        if image_numpy.shape[0] == 1:  # Grayscale\n",
        "            image_numpy = np.tile(image_numpy, (3, 1, 1))\n",
        "        elif image_numpy.shape[0] == 2:  # 2-Channel SAR\n",
        "            image_numpy = np.tile(image_numpy[0:1, :, :], (3, 1, 1))\n",
        "        # --- END OF FIX ---\n",
        "\n",
        "        image_numpy = (np.transpose(image_numpy, (1, 2, 0)) + 1) / 2.0 * 255.0\n",
        "    else:\n",
        "        image_numpy = input_image\n",
        "    return image_numpy.astype(imtype)\n",
        "\n",
        "\n",
        "def save_image(image_numpy, image_path, aspect_ratio=1.0):\n",
        "    \"\"\"Save a numpy image to the disk\"\"\"\n",
        "    image_pil = Image.fromarray(image_numpy)\n",
        "    h, w, _ = image_numpy.shape\n",
        "    if aspect_ratio > 1.0:\n",
        "        image_pil = image_pil.resize((h, int(w * aspect_ratio)), Image.BICUBIC)\n",
        "    if aspect_ratio < 1.0:\n",
        "        image_pil = image_pil.resize((int(h / aspect_ratio), w), Image.BICUBIC)\n",
        "    image_pil.save(image_path)\n",
        "\n",
        "\n",
        "def mkdirs(paths):\n",
        "    \"\"\"create empty directories if they don't exist\"\"\"\n",
        "    if isinstance(paths, list) and not isinstance(paths, str):\n",
        "        for path in paths:\n",
        "            mkdir(path)\n",
        "    else:\n",
        "        mkdir(paths)\n",
        "\n",
        "\n",
        "def mkdir(path):\n",
        "    \"\"\"create a single empty directory if it doesn't exist\"\"\"\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHRwk1Z9fEhA",
        "outputId": "1000875d-6a68-4611-fd06-aded2374fb8e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting util/util.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TRAINING"
      ],
      "metadata": {
        "id": "kORu9cpbBwe7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py \\\n",
        "  --dataroot /content/drive/MyDrive/cyclegans_new/preprocess/sar_to_rgb/ \\\n",
        "  --name sar2rgb_perceptual \\\n",
        "  --model cycle_gan \\\n",
        "  --netG resnet_9blocks \\\n",
        "  --dataset_mode unaligned_npy \\\n",
        "  --input_nc 2 \\\n",
        "  --output_nc 3 \\\n",
        "  --no_flip \\\n",
        "  --lambda_identity 0 \\\n",
        "  --lr 0.0001 \\\n",
        "  --lambda_perceptual 1.0\n",
        "  --continue_train \\\n",
        "  --epoch_count 11\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whfASAGEc0vG",
        "outputId": "962c46c7-6393-45ff-f3ff-c1e0d88f821d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dataloader files for .npy format have been created/patched.\n",
            "✅ Patched cycle_gan_model.py with Perceptual Loss.\n",
            "----------------- Options ---------------\n",
            "               batch_size: 1                             \n",
            "                    beta1: 0.5                           \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "           continue_train: True                          \t[default: False]\n",
            "                crop_size: 256                           \n",
            "                 dataroot: /content/drive/MyDrive/cyclegans_new/preprocess/sar_to_rgb/\t[default: None]\n",
            "             dataset_mode: unaligned_npy                 \t[default: unaligned]\n",
            "                direction: AtoB                          \n",
            "              display_env: main                          \n",
            "             display_freq: 400                           \n",
            "               display_id: 1                             \n",
            "            display_ncols: 4                             \n",
            "             display_port: 8097                          \n",
            "           display_server: http://localhost              \n",
            "          display_winsize: 256                           \n",
            "                    epoch: latest                        \n",
            "              epoch_count: 13                            \t[default: 1]\n",
            "                 gan_mode: lsgan                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 2                             \t[default: 3]\n",
            "                  isTrain: True                          \t[default: None]\n",
            "                 lambda_A: 10.0                          \n",
            "                 lambda_B: 10.0                          \n",
            "          lambda_identity: 0.0                           \t[default: 0.5]\n",
            "        lambda_perceptual: 1.0                           \n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 286                           \n",
            "                       lr: 0.0001                        \t[default: 0.0002]\n",
            "           lr_decay_iters: 50                            \n",
            "                lr_policy: linear                        \n",
            "         max_dataset_size: inf                           \n",
            "                    model: cycle_gan                     \n",
            "                 n_epochs: 100                           \n",
            "           n_epochs_decay: 100                           \n",
            "               n_layers_D: 3                             \n",
            "                     name: sar2rgb_perceptual            \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_9blocks                \n",
            "                      ngf: 64                            \n",
            "               no_dropout: True                          \n",
            "                  no_flip: True                          \t[default: False]\n",
            "                  no_html: False                         \n",
            "                     norm: instance                      \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: train                         \n",
            "                pool_size: 50                            \n",
            "               preprocess: resize_and_crop               \n",
            "               print_freq: 100                           \n",
            "             save_by_iter: False                         \n",
            "          save_epoch_freq: 5                             \n",
            "         save_latest_freq: 5000                          \n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "         update_html_freq: 1000                          \n",
            "                use_wandb: False                         \n",
            "                  verbose: False                         \n",
            "       wandb_project_name: CycleGAN-and-pix2pix          \n",
            "----------------- End -------------------\n",
            "dataset [UnalignedNpyDataset] was created\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "The number of training images = 1977\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n",
            "100% 548M/548M [00:05<00:00, 109MB/s] \n",
            "model [CycleGANModel] was created\n",
            "loading the model from ./checkpoints/sar2rgb_perceptual/latest_net_G_A.pth\n",
            "loading the model from ./checkpoints/sar2rgb_perceptual/latest_net_G_B.pth\n",
            "loading the model from ./checkpoints/sar2rgb_perceptual/latest_net_D_A.pth\n",
            "loading the model from ./checkpoints/sar2rgb_perceptual/latest_net_D_B.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G_A] Total number of parameters : 11.375 M\n",
            "[Network G_B] Total number of parameters : 11.375 M\n",
            "[Network D_A] Total number of parameters : 2.765 M\n",
            "[Network D_B] Total number of parameters : 2.764 M\n",
            "-----------------------------------------------\n",
            "Setting up a new session...\n",
            "Exception in user code:\n",
            "------------------------------------------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\", line 198, in _new_conn\n",
            "    sock = connection.create_connection(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/util/connection.py\", line 85, in create_connection\n",
            "    raise err\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/util/connection.py\", line 73, in create_connection\n",
            "    sock.connect(sa)\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
            "    response = self._make_request(\n",
            "               ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\", line 493, in _make_request\n",
            "    conn.request(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\", line 494, in request\n",
            "    self.endheaders()\n",
            "  File \"/usr/lib/python3.11/http/client.py\", line 1298, in endheaders\n",
            "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
            "  File \"/usr/lib/python3.11/http/client.py\", line 1058, in _send_output\n",
            "    self.send(msg)\n",
            "  File \"/usr/lib/python3.11/http/client.py\", line 996, in send\n",
            "    self.connect()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\", line 325, in connect\n",
            "    self.sock = self._new_conn()\n",
            "                ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\", line 213, in _new_conn\n",
            "    raise NewConnectionError(\n",
            "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x13a901241310>: Failed to establish a new connection: [Errno 111] Connection refused\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/requests/adapters.py\", line 667, in send\n",
            "    resp = conn.urlopen(\n",
            "           ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\", line 841, in urlopen\n",
            "    retries = retries.increment(\n",
            "              ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/util/retry.py\", line 519, in increment\n",
            "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/main (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x13a901241310>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/visdom/__init__.py\", line 756, in _send\n",
            "    return self._handle_post(\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/visdom/__init__.py\", line 720, in _handle_post\n",
            "    r = self.session.post(url, data=data)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/requests/sessions.py\", line 637, in post\n",
            "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/requests/sessions.py\", line 589, in request\n",
            "    resp = self.send(prep, **send_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/requests/sessions.py\", line 703, in send\n",
            "    r = adapter.send(request, **kwargs)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/requests/adapters.py\", line 700, in send\n",
            "    raise ConnectionError(e, request=request)\n",
            "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/main (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x13a901241310>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "[Errno 99] Cannot assign requested address\n",
            "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
            "[Errno 99] Cannot assign requested address\n",
            "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
            "[Errno 99] Cannot assign requested address\n",
            "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
            "Visdom python client failed to establish socket to get messages from the server. This feature is optional and can be disabled by initializing Visdom with `use_incoming_socket=False`, which will prevent waiting for this request to timeout.\n",
            "\n",
            "\n",
            "Could not connect to Visdom server. \n",
            " Trying to start a server....\n",
            "Command: /usr/bin/python3 -m visdom.server -p 8097 &>/dev/null &\n",
            "create web directory ./checkpoints/sar2rgb_perceptual/web...\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\n",
            "learning rate 0.0001000 -> 0.0001000\n",
            "[Errno 99] Cannot assign requested address\n",
            "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
            "[Errno 99] Cannot assign requested address\n",
            "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
            "(epoch: 13, iters: 100, time: 0.482, data: 1.669) D_A: 0.090 G_A: 1.020 cycle_A: 1.166 idt_A: 0.000 D_B: 0.062 G_B: 0.537 cycle_B: 0.337 idt_B: 0.000 perceptual: 7.130 \n",
            "(epoch: 13, iters: 200, time: 0.492, data: 0.003) D_A: 0.012 G_A: 0.252 cycle_A: 1.749 idt_A: 0.000 D_B: 0.028 G_B: 1.140 cycle_B: 0.537 idt_B: 0.000 perceptual: 11.335 \n",
            "(epoch: 13, iters: 300, time: 0.508, data: 0.005) D_A: 0.023 G_A: 0.522 cycle_A: 1.685 idt_A: 0.000 D_B: 0.021 G_B: 0.853 cycle_B: 0.704 idt_B: 0.000 perceptual: 10.418 \n",
            "(epoch: 13, iters: 400, time: 5.274, data: 0.004) D_A: 0.115 G_A: 1.117 cycle_A: 6.902 idt_A: 0.000 D_B: 0.127 G_B: 0.279 cycle_B: 0.420 idt_B: 0.000 perceptual: 11.798 \n",
            "(epoch: 13, iters: 500, time: 0.506, data: 0.002) D_A: 0.082 G_A: 0.291 cycle_A: 2.148 idt_A: 0.000 D_B: 0.054 G_B: 0.411 cycle_B: 0.452 idt_B: 0.000 perceptual: 9.483 \n",
            "(epoch: 13, iters: 600, time: 0.515, data: 0.003) D_A: 0.153 G_A: 1.577 cycle_A: 3.625 idt_A: 0.000 D_B: 0.038 G_B: 0.708 cycle_B: 0.458 idt_B: 0.000 perceptual: 11.105 \n",
            "(epoch: 13, iters: 700, time: 0.514, data: 0.002) D_A: 0.114 G_A: 0.464 cycle_A: 3.172 idt_A: 0.000 D_B: 0.013 G_B: 0.988 cycle_B: 0.493 idt_B: 0.000 perceptual: 9.922 \n",
            "(epoch: 13, iters: 800, time: 0.691, data: 0.001) D_A: 0.098 G_A: 0.195 cycle_A: 2.081 idt_A: 0.000 D_B: 0.053 G_B: 0.970 cycle_B: 1.837 idt_B: 0.000 perceptual: 15.876 \n",
            "(epoch: 13, iters: 900, time: 0.515, data: 0.002) D_A: 0.084 G_A: 0.278 cycle_A: 1.016 idt_A: 0.000 D_B: 0.078 G_B: 0.437 cycle_B: 1.377 idt_B: 0.000 perceptual: 8.155 \n",
            "(epoch: 13, iters: 1000, time: 0.514, data: 0.002) D_A: 0.017 G_A: 0.983 cycle_A: 1.158 idt_A: 0.000 D_B: 0.016 G_B: 0.718 cycle_B: 0.976 idt_B: 0.000 perceptual: 9.692 \n",
            "(epoch: 13, iters: 1100, time: 0.515, data: 0.002) D_A: 0.051 G_A: 0.582 cycle_A: 0.884 idt_A: 0.000 D_B: 0.123 G_B: 1.027 cycle_B: 0.950 idt_B: 0.000 perceptual: 9.420 \n",
            "(epoch: 13, iters: 1200, time: 0.677, data: 0.003) D_A: 0.103 G_A: 0.396 cycle_A: 6.442 idt_A: 0.000 D_B: 0.020 G_B: 0.923 cycle_B: 1.101 idt_B: 0.000 perceptual: 13.651 \n",
            "(epoch: 13, iters: 1300, time: 0.513, data: 0.003) D_A: 0.037 G_A: 0.295 cycle_A: 1.553 idt_A: 0.000 D_B: 0.056 G_B: 0.791 cycle_B: 0.574 idt_B: 0.000 perceptual: 9.103 \n",
            "(epoch: 13, iters: 1400, time: 0.513, data: 0.001) D_A: 0.031 G_A: 0.915 cycle_A: 2.413 idt_A: 0.000 D_B: 0.054 G_B: 0.797 cycle_B: 0.341 idt_B: 0.000 perceptual: 6.842 \n",
            "(epoch: 13, iters: 1500, time: 0.516, data: 0.002) D_A: 0.238 G_A: 1.022 cycle_A: 0.686 idt_A: 0.000 D_B: 0.053 G_B: 0.313 cycle_B: 1.757 idt_B: 0.000 perceptual: 11.161 \n",
            "(epoch: 13, iters: 1600, time: 0.850, data: 0.002) D_A: 0.142 G_A: 0.800 cycle_A: 1.862 idt_A: 0.000 D_B: 0.093 G_B: 0.594 cycle_B: 1.380 idt_B: 0.000 perceptual: 8.880 \n",
            "(epoch: 13, iters: 1700, time: 0.515, data: 0.002) D_A: 0.169 G_A: 0.320 cycle_A: 0.844 idt_A: 0.000 D_B: 0.159 G_B: 0.452 cycle_B: 0.715 idt_B: 0.000 perceptual: 8.285 \n",
            "(epoch: 13, iters: 1800, time: 0.515, data: 0.003) D_A: 0.042 G_A: 0.564 cycle_A: 1.943 idt_A: 0.000 D_B: 0.083 G_B: 0.777 cycle_B: 0.587 idt_B: 0.000 perceptual: 14.196 \n",
            "(epoch: 13, iters: 1900, time: 0.513, data: 0.003) D_A: 0.024 G_A: 0.773 cycle_A: 2.629 idt_A: 0.000 D_B: 0.065 G_B: 0.865 cycle_B: 1.282 idt_B: 0.000 perceptual: 10.966 \n",
            "End of epoch 13 / 200 \t Time Taken: 836 sec\n",
            "learning rate 0.0001000 -> 0.0001000\n",
            "(epoch: 14, iters: 23, time: 4.022, data: 0.001) D_A: 0.090 G_A: 0.677 cycle_A: 2.209 idt_A: 0.000 D_B: 0.125 G_B: 0.293 cycle_B: 2.560 idt_B: 0.000 perceptual: 9.950 \n",
            "(epoch: 14, iters: 123, time: 0.513, data: 0.003) D_A: 0.100 G_A: 0.952 cycle_A: 6.232 idt_A: 0.000 D_B: 0.031 G_B: 1.135 cycle_B: 0.900 idt_B: 0.000 perceptual: 14.846 \n",
            "(epoch: 14, iters: 223, time: 0.513, data: 0.002) D_A: 0.061 G_A: 1.352 cycle_A: 5.451 idt_A: 0.000 D_B: 0.046 G_B: 0.670 cycle_B: 0.308 idt_B: 0.000 perceptual: 15.181 \n",
            "(epoch: 14, iters: 323, time: 0.510, data: 0.001) D_A: 0.040 G_A: 0.583 cycle_A: 2.081 idt_A: 0.000 D_B: 0.051 G_B: 0.658 cycle_B: 1.726 idt_B: 0.000 perceptual: 14.446 \n",
            "(epoch: 14, iters: 423, time: 0.753, data: 0.013) D_A: 0.274 G_A: 0.657 cycle_A: 3.350 idt_A: 0.000 D_B: 0.049 G_B: 1.296 cycle_B: 0.732 idt_B: 0.000 perceptual: 12.251 \n",
            "(epoch: 14, iters: 523, time: 0.510, data: 0.006) D_A: 0.091 G_A: 0.857 cycle_A: 0.959 idt_A: 0.000 D_B: 0.215 G_B: 0.154 cycle_B: 0.465 idt_B: 0.000 perceptual: 9.504 \n",
            "(epoch: 14, iters: 623, time: 0.515, data: 0.002) D_A: 0.021 G_A: 0.888 cycle_A: 2.978 idt_A: 0.000 D_B: 0.079 G_B: 1.231 cycle_B: 1.275 idt_B: 0.000 perceptual: 11.711 \n",
            "(epoch: 14, iters: 723, time: 0.511, data: 0.002) D_A: 0.057 G_A: 0.749 cycle_A: 3.599 idt_A: 0.000 D_B: 0.031 G_B: 0.661 cycle_B: 0.513 idt_B: 0.000 perceptual: 13.347 \n",
            "(epoch: 14, iters: 823, time: 0.762, data: 0.008) D_A: 0.096 G_A: 0.778 cycle_A: 2.067 idt_A: 0.000 D_B: 0.090 G_B: 1.098 cycle_B: 0.268 idt_B: 0.000 perceptual: 7.208 \n",
            "(epoch: 14, iters: 923, time: 0.515, data: 0.001) D_A: 0.294 G_A: 0.111 cycle_A: 1.623 idt_A: 0.000 D_B: 0.259 G_B: 1.057 cycle_B: 3.342 idt_B: 0.000 perceptual: 13.936 \n",
            "(epoch: 14, iters: 1023, time: 0.515, data: 0.001) D_A: 0.038 G_A: 1.037 cycle_A: 1.468 idt_A: 0.000 D_B: 0.051 G_B: 0.521 cycle_B: 0.288 idt_B: 0.000 perceptual: 6.919 \n",
            "(epoch: 14, iters: 1123, time: 0.517, data: 0.004) D_A: 0.019 G_A: 0.695 cycle_A: 2.415 idt_A: 0.000 D_B: 0.129 G_B: 0.765 cycle_B: 0.556 idt_B: 0.000 perceptual: 7.354 \n",
            "(epoch: 14, iters: 1223, time: 0.691, data: 0.004) D_A: 0.081 G_A: 0.437 cycle_A: 1.026 idt_A: 0.000 D_B: 0.068 G_B: 1.107 cycle_B: 1.752 idt_B: 0.000 perceptual: 9.202 \n",
            "(epoch: 14, iters: 1323, time: 0.513, data: 0.001) D_A: 0.060 G_A: 0.501 cycle_A: 2.398 idt_A: 0.000 D_B: 0.012 G_B: 1.218 cycle_B: 0.407 idt_B: 0.000 perceptual: 8.208 \n",
            "(epoch: 14, iters: 1423, time: 0.512, data: 0.001) D_A: 0.063 G_A: 1.062 cycle_A: 1.169 idt_A: 0.000 D_B: 0.052 G_B: 0.572 cycle_B: 1.552 idt_B: 0.000 perceptual: 11.600 \n",
            "(epoch: 14, iters: 1523, time: 0.520, data: 0.003) D_A: 0.057 G_A: 0.587 cycle_A: 1.889 idt_A: 0.000 D_B: 0.047 G_B: 1.330 cycle_B: 1.082 idt_B: 0.000 perceptual: 8.058 \n",
            "(epoch: 14, iters: 1623, time: 0.700, data: 0.006) D_A: 0.059 G_A: 1.042 cycle_A: 2.889 idt_A: 0.000 D_B: 0.076 G_B: 0.383 cycle_B: 0.630 idt_B: 0.000 perceptual: 10.531 \n",
            "(epoch: 14, iters: 1723, time: 0.519, data: 0.002) D_A: 0.252 G_A: 0.131 cycle_A: 7.898 idt_A: 0.000 D_B: 0.017 G_B: 0.505 cycle_B: 1.045 idt_B: 0.000 perceptual: 22.370 \n",
            "(epoch: 14, iters: 1823, time: 0.513, data: 0.002) D_A: 0.176 G_A: 0.254 cycle_A: 1.055 idt_A: 0.000 D_B: 0.287 G_B: 1.859 cycle_B: 0.469 idt_B: 0.000 perceptual: 9.724 \n",
            "(epoch: 14, iters: 1923, time: 0.513, data: 0.004) D_A: 0.052 G_A: 0.585 cycle_A: 3.192 idt_A: 0.000 D_B: 0.125 G_B: 0.301 cycle_B: 0.451 idt_B: 0.000 perceptual: 8.171 \n",
            "End of epoch 14 / 200 \t Time Taken: 783 sec\n",
            "learning rate 0.0001000 -> 0.0001000\n",
            "(epoch: 15, iters: 46, time: 4.037, data: 0.002) D_A: 0.112 G_A: 0.443 cycle_A: 2.414 idt_A: 0.000 D_B: 0.071 G_B: 0.936 cycle_B: 0.550 idt_B: 0.000 perceptual: 9.285 \n",
            "(epoch: 15, iters: 146, time: 0.515, data: 0.002) D_A: 0.035 G_A: 0.898 cycle_A: 2.628 idt_A: 0.000 D_B: 0.074 G_B: 0.526 cycle_B: 0.467 idt_B: 0.000 perceptual: 9.918 \n",
            "(epoch: 15, iters: 246, time: 0.511, data: 0.002) D_A: 0.022 G_A: 0.757 cycle_A: 0.962 idt_A: 0.000 D_B: 0.045 G_B: 0.721 cycle_B: 1.692 idt_B: 0.000 perceptual: 8.778 \n",
            "(epoch: 15, iters: 346, time: 0.516, data: 0.002) D_A: 0.072 G_A: 0.424 cycle_A: 3.876 idt_A: 0.000 D_B: 0.137 G_B: 0.518 cycle_B: 0.606 idt_B: 0.000 perceptual: 9.512 \n",
            "(epoch: 15, iters: 446, time: 0.685, data: 0.002) D_A: 0.076 G_A: 0.706 cycle_A: 6.727 idt_A: 0.000 D_B: 0.030 G_B: 0.698 cycle_B: 0.824 idt_B: 0.000 perceptual: 14.642 \n",
            "(epoch: 15, iters: 546, time: 0.513, data: 0.003) D_A: 0.095 G_A: 0.700 cycle_A: 2.715 idt_A: 0.000 D_B: 0.075 G_B: 0.504 cycle_B: 1.943 idt_B: 0.000 perceptual: 15.592 \n",
            "(epoch: 15, iters: 646, time: 0.513, data: 0.004) D_A: 0.019 G_A: 0.590 cycle_A: 1.031 idt_A: 0.000 D_B: 0.034 G_B: 0.652 cycle_B: 0.224 idt_B: 0.000 perceptual: 6.935 \n",
            "(epoch: 15, iters: 746, time: 0.513, data: 0.003) D_A: 0.020 G_A: 0.258 cycle_A: 1.806 idt_A: 0.000 D_B: 0.067 G_B: 0.601 cycle_B: 0.216 idt_B: 0.000 perceptual: 7.376 \n",
            "(epoch: 15, iters: 846, time: 0.696, data: 0.002) D_A: 0.048 G_A: 0.790 cycle_A: 2.621 idt_A: 0.000 D_B: 0.036 G_B: 0.331 cycle_B: 0.317 idt_B: 0.000 perceptual: 8.367 \n",
            "(epoch: 15, iters: 946, time: 0.517, data: 0.002) D_A: 0.204 G_A: 0.569 cycle_A: 0.930 idt_A: 0.000 D_B: 0.193 G_B: 0.900 cycle_B: 0.239 idt_B: 0.000 perceptual: 7.127 \n",
            "(epoch: 15, iters: 1046, time: 0.511, data: 0.004) D_A: 0.055 G_A: 0.735 cycle_A: 1.253 idt_A: 0.000 D_B: 0.129 G_B: 1.488 cycle_B: 1.028 idt_B: 0.000 perceptual: 9.952 \n",
            "saving the latest model (epoch 15, total_iters 5000)\n",
            "(epoch: 15, iters: 1146, time: 0.517, data: 0.002) D_A: 0.204 G_A: 0.595 cycle_A: 2.169 idt_A: 0.000 D_B: 0.020 G_B: 0.222 cycle_B: 0.316 idt_B: 0.000 perceptual: 8.339 \n",
            "(epoch: 15, iters: 1246, time: 0.700, data: 0.003) D_A: 0.119 G_A: 0.975 cycle_A: 6.948 idt_A: 0.000 D_B: 0.032 G_B: 0.783 cycle_B: 0.589 idt_B: 0.000 perceptual: 10.822 \n",
            "(epoch: 15, iters: 1346, time: 0.518, data: 0.003) D_A: 0.054 G_A: 0.314 cycle_A: 1.014 idt_A: 0.000 D_B: 0.176 G_B: 0.215 cycle_B: 0.970 idt_B: 0.000 perceptual: 8.337 \n",
            "(epoch: 15, iters: 1446, time: 0.511, data: 0.004) D_A: 0.047 G_A: 0.720 cycle_A: 1.484 idt_A: 0.000 D_B: 0.054 G_B: 0.616 cycle_B: 0.734 idt_B: 0.000 perceptual: 9.226 \n",
            "(epoch: 15, iters: 1546, time: 0.512, data: 0.002) D_A: 0.058 G_A: 0.653 cycle_A: 2.859 idt_A: 0.000 D_B: 0.030 G_B: 0.822 cycle_B: 0.441 idt_B: 0.000 perceptual: 9.653 \n",
            "(epoch: 15, iters: 1646, time: 0.799, data: 0.003) D_A: 0.207 G_A: 0.203 cycle_A: 0.945 idt_A: 0.000 D_B: 0.024 G_B: 0.721 cycle_B: 0.149 idt_B: 0.000 perceptual: 7.176 \n",
            "(epoch: 15, iters: 1746, time: 0.518, data: 0.002) D_A: 0.106 G_A: 0.406 cycle_A: 1.269 idt_A: 0.000 D_B: 0.026 G_B: 0.854 cycle_B: 4.121 idt_B: 0.000 perceptual: 10.122 \n",
            "(epoch: 15, iters: 1846, time: 0.514, data: 0.002) D_A: 0.023 G_A: 0.403 cycle_A: 1.138 idt_A: 0.000 D_B: 0.080 G_B: 1.074 cycle_B: 2.266 idt_B: 0.000 perceptual: 14.006 \n",
            "(epoch: 15, iters: 1946, time: 0.514, data: 0.002) D_A: 0.055 G_A: 0.558 cycle_A: 1.767 idt_A: 0.000 D_B: 0.119 G_B: 0.762 cycle_B: 0.339 idt_B: 0.000 perceptual: 8.348 \n",
            "saving the model at the end of epoch 15, iters 5931\n",
            "End of epoch 15 / 200 \t Time Taken: 788 sec\n",
            "learning rate 0.0001000 -> 0.0001000\n",
            "(epoch: 16, iters: 69, time: 1.231, data: 0.002) D_A: 0.091 G_A: 0.672 cycle_A: 1.927 idt_A: 0.000 D_B: 0.069 G_B: 0.554 cycle_B: 0.603 idt_B: 0.000 perceptual: 12.417 \n",
            "(epoch: 16, iters: 169, time: 0.509, data: 0.002) D_A: 0.013 G_A: 0.944 cycle_A: 2.295 idt_A: 0.000 D_B: 0.088 G_B: 0.609 cycle_B: 0.687 idt_B: 0.000 perceptual: 9.532 \n",
            "(epoch: 16, iters: 269, time: 0.515, data: 0.014) D_A: 0.055 G_A: 0.510 cycle_A: 1.918 idt_A: 0.000 D_B: 0.074 G_B: 1.062 cycle_B: 0.691 idt_B: 0.000 perceptual: 7.538 \n",
            "(epoch: 16, iters: 369, time: 0.515, data: 0.002) D_A: 0.283 G_A: 0.963 cycle_A: 2.204 idt_A: 0.000 D_B: 0.032 G_B: 0.863 cycle_B: 0.580 idt_B: 0.000 perceptual: 10.098 \n",
            "(epoch: 16, iters: 469, time: 0.681, data: 0.002) D_A: 0.082 G_A: 0.485 cycle_A: 2.078 idt_A: 0.000 D_B: 0.026 G_B: 0.704 cycle_B: 1.387 idt_B: 0.000 perceptual: 12.944 \n",
            "(epoch: 16, iters: 569, time: 0.513, data: 0.002) D_A: 0.020 G_A: 0.579 cycle_A: 1.538 idt_A: 0.000 D_B: 0.026 G_B: 1.251 cycle_B: 1.937 idt_B: 0.000 perceptual: 10.260 \n",
            "(epoch: 16, iters: 669, time: 0.513, data: 0.002) D_A: 0.125 G_A: 0.133 cycle_A: 0.749 idt_A: 0.000 D_B: 0.101 G_B: 0.562 cycle_B: 1.313 idt_B: 0.000 perceptual: 7.426 \n",
            "(epoch: 16, iters: 769, time: 0.513, data: 0.002) D_A: 0.048 G_A: 0.911 cycle_A: 1.403 idt_A: 0.000 D_B: 0.038 G_B: 0.498 cycle_B: 0.320 idt_B: 0.000 perceptual: 7.918 \n",
            "(epoch: 16, iters: 869, time: 0.863, data: 0.002) D_A: 0.057 G_A: 0.527 cycle_A: 0.872 idt_A: 0.000 D_B: 0.162 G_B: 0.294 cycle_B: 0.748 idt_B: 0.000 perceptual: 9.643 \n",
            "(epoch: 16, iters: 969, time: 0.516, data: 0.002) D_A: 0.219 G_A: 0.480 cycle_A: 1.245 idt_A: 0.000 D_B: 0.077 G_B: 0.532 cycle_B: 0.435 idt_B: 0.000 perceptual: 7.838 \n",
            "(epoch: 16, iters: 1069, time: 0.516, data: 0.002) D_A: 0.427 G_A: 0.020 cycle_A: 2.662 idt_A: 0.000 D_B: 0.022 G_B: 0.315 cycle_B: 3.744 idt_B: 0.000 perceptual: 15.671 \n",
            "(epoch: 16, iters: 1169, time: 0.515, data: 0.002) D_A: 0.065 G_A: 0.730 cycle_A: 0.950 idt_A: 0.000 D_B: 0.055 G_B: 0.609 cycle_B: 0.676 idt_B: 0.000 perceptual: 6.574 \n",
            "(epoch: 16, iters: 1269, time: 0.696, data: 0.002) D_A: 0.140 G_A: 0.373 cycle_A: 1.706 idt_A: 0.000 D_B: 0.055 G_B: 0.959 cycle_B: 0.369 idt_B: 0.000 perceptual: 10.551 \n",
            "(epoch: 16, iters: 1369, time: 0.514, data: 0.002) D_A: 0.012 G_A: 0.529 cycle_A: 1.856 idt_A: 0.000 D_B: 0.021 G_B: 0.923 cycle_B: 7.120 idt_B: 0.000 perceptual: 15.550 \n",
            "(epoch: 16, iters: 1469, time: 0.515, data: 0.002) D_A: 0.278 G_A: 0.744 cycle_A: 1.435 idt_A: 0.000 D_B: 0.088 G_B: 0.138 cycle_B: 0.398 idt_B: 0.000 perceptual: 11.692 \n",
            "(epoch: 16, iters: 1569, time: 0.515, data: 0.007) D_A: 0.062 G_A: 0.811 cycle_A: 2.081 idt_A: 0.000 D_B: 0.055 G_B: 1.192 cycle_B: 0.582 idt_B: 0.000 perceptual: 9.723 \n",
            "(epoch: 16, iters: 1669, time: 0.701, data: 0.002) D_A: 0.059 G_A: 0.535 cycle_A: 4.851 idt_A: 0.000 D_B: 0.344 G_B: 0.625 cycle_B: 0.274 idt_B: 0.000 perceptual: 10.963 \n",
            "(epoch: 16, iters: 1769, time: 0.512, data: 0.003) D_A: 0.041 G_A: 0.965 cycle_A: 2.300 idt_A: 0.000 D_B: 0.025 G_B: 0.758 cycle_B: 0.606 idt_B: 0.000 perceptual: 9.317 \n",
            "(epoch: 16, iters: 1869, time: 0.515, data: 0.002) D_A: 0.132 G_A: 1.043 cycle_A: 5.686 idt_A: 0.000 D_B: 0.042 G_B: 0.797 cycle_B: 0.493 idt_B: 0.000 perceptual: 9.740 \n",
            "(epoch: 16, iters: 1969, time: 0.513, data: 0.002) D_A: 0.019 G_A: 1.144 cycle_A: 1.827 idt_A: 0.000 D_B: 0.018 G_B: 0.889 cycle_B: 1.491 idt_B: 0.000 perceptual: 6.240 \n",
            "End of epoch 16 / 200 \t Time Taken: 784 sec\n",
            "learning rate 0.0001000 -> 0.0001000\n",
            "(epoch: 17, iters: 92, time: 1.453, data: 0.002) D_A: 0.011 G_A: 0.976 cycle_A: 1.372 idt_A: 0.000 D_B: 0.132 G_B: 1.292 cycle_B: 0.822 idt_B: 0.000 perceptual: 9.196 \n",
            "(epoch: 17, iters: 192, time: 0.511, data: 0.011) D_A: 0.016 G_A: 0.640 cycle_A: 1.283 idt_A: 0.000 D_B: 0.056 G_B: 0.945 cycle_B: 1.536 idt_B: 0.000 perceptual: 10.532 \n",
            "(epoch: 17, iters: 292, time: 0.513, data: 0.002) D_A: 0.048 G_A: 0.589 cycle_A: 1.646 idt_A: 0.000 D_B: 0.021 G_B: 0.433 cycle_B: 0.598 idt_B: 0.000 perceptual: 7.867 \n",
            "(epoch: 17, iters: 392, time: 0.515, data: 0.002) D_A: 0.158 G_A: 0.269 cycle_A: 1.671 idt_A: 0.000 D_B: 0.044 G_B: 0.586 cycle_B: 0.529 idt_B: 0.000 perceptual: 10.142 \n",
            "(epoch: 17, iters: 492, time: 0.697, data: 0.002) D_A: 0.012 G_A: 1.002 cycle_A: 0.790 idt_A: 0.000 D_B: 0.020 G_B: 0.792 cycle_B: 1.563 idt_B: 0.000 perceptual: 8.967 \n",
            "(epoch: 17, iters: 592, time: 0.514, data: 0.002) D_A: 0.018 G_A: 0.774 cycle_A: 1.045 idt_A: 0.000 D_B: 0.025 G_B: 1.012 cycle_B: 0.403 idt_B: 0.000 perceptual: 7.067 \n",
            "(epoch: 17, iters: 692, time: 0.518, data: 0.002) D_A: 0.020 G_A: 1.042 cycle_A: 1.501 idt_A: 0.000 D_B: 0.039 G_B: 0.747 cycle_B: 0.666 idt_B: 0.000 perceptual: 7.157 \n",
            "(epoch: 17, iters: 792, time: 0.513, data: 0.002) D_A: 0.271 G_A: 0.435 cycle_A: 2.691 idt_A: 0.000 D_B: 0.013 G_B: 0.143 cycle_B: 0.473 idt_B: 0.000 perceptual: 10.600 \n",
            "(epoch: 17, iters: 892, time: 0.918, data: 0.003) D_A: 0.276 G_A: 0.091 cycle_A: 2.100 idt_A: 0.000 D_B: 0.036 G_B: 0.684 cycle_B: 0.266 idt_B: 0.000 perceptual: 8.445 \n",
            "(epoch: 17, iters: 992, time: 0.517, data: 0.005) D_A: 0.082 G_A: 1.353 cycle_A: 1.209 idt_A: 0.000 D_B: 0.035 G_B: 0.512 cycle_B: 0.433 idt_B: 0.000 perceptual: 9.518 \n",
            "(epoch: 17, iters: 1092, time: 0.516, data: 0.002) D_A: 0.036 G_A: 0.961 cycle_A: 1.225 idt_A: 0.000 D_B: 0.199 G_B: 0.203 cycle_B: 1.305 idt_B: 0.000 perceptual: 11.802 \n",
            "(epoch: 17, iters: 1192, time: 0.518, data: 0.002) D_A: 0.024 G_A: 1.040 cycle_A: 1.583 idt_A: 0.000 D_B: 0.038 G_B: 0.628 cycle_B: 0.259 idt_B: 0.000 perceptual: 8.655 \n",
            "(epoch: 17, iters: 1292, time: 0.674, data: 0.002) D_A: 0.029 G_A: 0.481 cycle_A: 0.900 idt_A: 0.000 D_B: 0.050 G_B: 0.375 cycle_B: 0.806 idt_B: 0.000 perceptual: 12.102 \n",
            "(epoch: 17, iters: 1392, time: 0.517, data: 0.002) D_A: 0.039 G_A: 0.595 cycle_A: 1.819 idt_A: 0.000 D_B: 0.043 G_B: 0.699 cycle_B: 0.319 idt_B: 0.000 perceptual: 7.299 \n",
            "(epoch: 17, iters: 1492, time: 0.517, data: 0.004) D_A: 0.035 G_A: 0.961 cycle_A: 3.942 idt_A: 0.000 D_B: 0.044 G_B: 1.082 cycle_B: 0.604 idt_B: 0.000 perceptual: 8.414 \n",
            "(epoch: 17, iters: 1592, time: 0.515, data: 0.002) D_A: 0.021 G_A: 1.058 cycle_A: 4.934 idt_A: 0.000 D_B: 0.014 G_B: 1.063 cycle_B: 0.543 idt_B: 0.000 perceptual: 13.096 \n",
            "(epoch: 17, iters: 1692, time: 0.724, data: 0.002) D_A: 0.059 G_A: 0.491 cycle_A: 2.035 idt_A: 0.000 D_B: 0.024 G_B: 1.033 cycle_B: 0.309 idt_B: 0.000 perceptual: 7.157 \n",
            "(epoch: 17, iters: 1792, time: 0.525, data: 0.002) D_A: 0.025 G_A: 1.058 cycle_A: 1.082 idt_A: 0.000 D_B: 0.056 G_B: 0.823 cycle_B: 4.116 idt_B: 0.000 perceptual: 10.506 \n",
            "(epoch: 17, iters: 1892, time: 0.515, data: 0.003) D_A: 0.025 G_A: 0.958 cycle_A: 1.153 idt_A: 0.000 D_B: 0.068 G_B: 0.534 cycle_B: 0.608 idt_B: 0.000 perceptual: 8.516 \n",
            "End of epoch 17 / 200 \t Time Taken: 782 sec\n",
            "learning rate 0.0001000 -> 0.0001000\n",
            "(epoch: 18, iters: 15, time: 0.516, data: 0.002) D_A: 0.045 G_A: 1.137 cycle_A: 1.297 idt_A: 0.000 D_B: 0.015 G_B: 1.123 cycle_B: 0.963 idt_B: 0.000 perceptual: 10.578 \n",
            "(epoch: 18, iters: 115, time: 1.032, data: 0.003) D_A: 0.050 G_A: 0.614 cycle_A: 1.328 idt_A: 0.000 D_B: 0.119 G_B: 0.413 cycle_B: 0.831 idt_B: 0.000 perceptual: 8.199 \n",
            "saving the latest model (epoch 18, total_iters 10000)\n",
            "(epoch: 18, iters: 215, time: 0.518, data: 0.002) D_A: 0.146 G_A: 0.504 cycle_A: 2.947 idt_A: 0.000 D_B: 0.164 G_B: 0.697 cycle_B: 5.367 idt_B: 0.000 perceptual: 13.763 \n",
            "(epoch: 18, iters: 315, time: 0.514, data: 0.005) D_A: 0.109 G_A: 0.340 cycle_A: 1.091 idt_A: 0.000 D_B: 0.066 G_B: 0.716 cycle_B: 0.438 idt_B: 0.000 perceptual: 7.761 \n",
            "(epoch: 18, iters: 415, time: 0.515, data: 0.002) D_A: 0.064 G_A: 0.257 cycle_A: 0.859 idt_A: 0.000 D_B: 0.084 G_B: 0.595 cycle_B: 0.707 idt_B: 0.000 perceptual: 9.593 \n",
            "(epoch: 18, iters: 515, time: 0.814, data: 0.002) D_A: 0.032 G_A: 0.802 cycle_A: 3.554 idt_A: 0.000 D_B: 0.026 G_B: 0.215 cycle_B: 1.220 idt_B: 0.000 perceptual: 9.247 \n",
            "(epoch: 18, iters: 615, time: 0.547, data: 0.002) D_A: 0.040 G_A: 0.615 cycle_A: 1.447 idt_A: 0.000 D_B: 0.011 G_B: 1.060 cycle_B: 1.494 idt_B: 0.000 perceptual: 9.124 \n",
            "(epoch: 18, iters: 715, time: 0.513, data: 0.002) D_A: 0.070 G_A: 0.928 cycle_A: 1.188 idt_A: 0.000 D_B: 0.543 G_B: 0.379 cycle_B: 0.607 idt_B: 0.000 perceptual: 7.551 \n",
            "(epoch: 18, iters: 815, time: 0.517, data: 0.002) D_A: 0.086 G_A: 0.409 cycle_A: 2.245 idt_A: 0.000 D_B: 0.010 G_B: 1.100 cycle_B: 1.066 idt_B: 0.000 perceptual: 8.884 \n",
            "(epoch: 18, iters: 915, time: 0.703, data: 0.002) D_A: 0.022 G_A: 0.486 cycle_A: 1.063 idt_A: 0.000 D_B: 0.045 G_B: 1.060 cycle_B: 0.304 idt_B: 0.000 perceptual: 8.538 \n",
            "(epoch: 18, iters: 1015, time: 0.515, data: 0.002) D_A: 0.047 G_A: 1.098 cycle_A: 1.657 idt_A: 0.000 D_B: 0.168 G_B: 0.518 cycle_B: 0.823 idt_B: 0.000 perceptual: 11.358 \n",
            "(epoch: 18, iters: 1115, time: 0.513, data: 0.002) D_A: 0.036 G_A: 0.867 cycle_A: 7.480 idt_A: 0.000 D_B: 0.014 G_B: 0.622 cycle_B: 0.608 idt_B: 0.000 perceptual: 11.381 \n",
            "(epoch: 18, iters: 1215, time: 0.509, data: 0.002) D_A: 0.055 G_A: 0.591 cycle_A: 0.905 idt_A: 0.000 D_B: 0.126 G_B: 0.292 cycle_B: 0.619 idt_B: 0.000 perceptual: 7.348 \n",
            "(epoch: 18, iters: 1315, time: 0.784, data: 0.002) D_A: 0.019 G_A: 0.841 cycle_A: 0.773 idt_A: 0.000 D_B: 0.159 G_B: 0.303 cycle_B: 0.740 idt_B: 0.000 perceptual: 6.359 \n",
            "(epoch: 18, iters: 1415, time: 0.514, data: 0.002) D_A: 0.152 G_A: 1.151 cycle_A: 1.632 idt_A: 0.000 D_B: 0.111 G_B: 0.332 cycle_B: 0.321 idt_B: 0.000 perceptual: 7.195 \n",
            "(epoch: 18, iters: 1515, time: 0.514, data: 0.002) D_A: 0.147 G_A: 0.565 cycle_A: 1.994 idt_A: 0.000 D_B: 0.063 G_B: 0.248 cycle_B: 0.393 idt_B: 0.000 perceptual: 10.815 \n",
            "(epoch: 18, iters: 1615, time: 0.511, data: 0.002) D_A: 0.344 G_A: 0.782 cycle_A: 1.044 idt_A: 0.000 D_B: 0.055 G_B: 0.051 cycle_B: 0.441 idt_B: 0.000 perceptual: 8.634 \n",
            "(epoch: 18, iters: 1715, time: 0.750, data: 0.002) D_A: 0.046 G_A: 0.585 cycle_A: 2.852 idt_A: 0.000 D_B: 0.085 G_B: 0.902 cycle_B: 3.235 idt_B: 0.000 perceptual: 9.790 \n",
            "(epoch: 18, iters: 1815, time: 0.513, data: 0.008) D_A: 0.023 G_A: 0.835 cycle_A: 0.805 idt_A: 0.000 D_B: 0.144 G_B: 0.254 cycle_B: 2.409 idt_B: 0.000 perceptual: 9.544 \n",
            "(epoch: 18, iters: 1915, time: 0.514, data: 0.002) D_A: 0.082 G_A: 0.542 cycle_A: 3.826 idt_A: 0.000 D_B: 0.022 G_B: 0.972 cycle_B: 0.538 idt_B: 0.000 perceptual: 11.780 \n",
            "End of epoch 18 / 200 \t Time Taken: 784 sec\n",
            "learning rate 0.0001000 -> 0.0001000\n",
            "(epoch: 19, iters: 38, time: 0.513, data: 0.002) D_A: 0.057 G_A: 0.533 cycle_A: 1.258 idt_A: 0.000 D_B: 0.172 G_B: 0.727 cycle_B: 0.311 idt_B: 0.000 perceptual: 7.241 \n",
            "(epoch: 19, iters: 138, time: 1.074, data: 0.002) D_A: 0.151 G_A: 1.179 cycle_A: 1.014 idt_A: 0.000 D_B: 0.036 G_B: 0.951 cycle_B: 1.108 idt_B: 0.000 perceptual: 8.278 \n",
            "(epoch: 19, iters: 238, time: 0.513, data: 0.002) D_A: 0.053 G_A: 1.013 cycle_A: 0.961 idt_A: 0.000 D_B: 0.022 G_B: 0.536 cycle_B: 0.599 idt_B: 0.000 perceptual: 9.456 \n",
            "(epoch: 19, iters: 338, time: 0.512, data: 0.002) D_A: 0.136 G_A: 0.876 cycle_A: 0.902 idt_A: 0.000 D_B: 0.092 G_B: 0.436 cycle_B: 0.493 idt_B: 0.000 perceptual: 8.419 \n",
            "(epoch: 19, iters: 438, time: 0.512, data: 0.002) D_A: 0.051 G_A: 0.673 cycle_A: 1.110 idt_A: 0.000 D_B: 0.011 G_B: 0.631 cycle_B: 0.426 idt_B: 0.000 perceptual: 7.883 \n",
            "(epoch: 19, iters: 538, time: 0.682, data: 0.002) D_A: 0.034 G_A: 0.601 cycle_A: 1.629 idt_A: 0.000 D_B: 0.033 G_B: 0.800 cycle_B: 1.188 idt_B: 0.000 perceptual: 14.471 \n",
            "(epoch: 19, iters: 638, time: 0.512, data: 0.002) D_A: 0.131 G_A: 0.457 cycle_A: 0.929 idt_A: 0.000 D_B: 0.115 G_B: 0.380 cycle_B: 0.357 idt_B: 0.000 perceptual: 9.426 \n",
            "(epoch: 19, iters: 738, time: 0.515, data: 0.002) D_A: 0.092 G_A: 1.287 cycle_A: 1.609 idt_A: 0.000 D_B: 0.108 G_B: 0.403 cycle_B: 1.297 idt_B: 0.000 perceptual: 8.490 \n",
            "(epoch: 19, iters: 838, time: 0.514, data: 0.004) D_A: 0.052 G_A: 0.536 cycle_A: 1.177 idt_A: 0.000 D_B: 0.077 G_B: 0.466 cycle_B: 0.291 idt_B: 0.000 perceptual: 7.276 \n",
            "(epoch: 19, iters: 938, time: 0.689, data: 0.002) D_A: 0.012 G_A: 0.346 cycle_A: 3.202 idt_A: 0.000 D_B: 0.119 G_B: 1.194 cycle_B: 0.731 idt_B: 0.000 perceptual: 14.615 \n",
            "(epoch: 19, iters: 1038, time: 0.511, data: 0.002) D_A: 0.057 G_A: 1.248 cycle_A: 1.171 idt_A: 0.000 D_B: 0.039 G_B: 0.476 cycle_B: 1.095 idt_B: 0.000 perceptual: 7.303 \n",
            "(epoch: 19, iters: 1138, time: 0.513, data: 0.002) D_A: 0.096 G_A: 0.968 cycle_A: 1.197 idt_A: 0.000 D_B: 0.029 G_B: 0.594 cycle_B: 0.640 idt_B: 0.000 perceptual: 8.072 \n",
            "(epoch: 19, iters: 1238, time: 0.517, data: 0.002) D_A: 0.030 G_A: 0.865 cycle_A: 2.249 idt_A: 0.000 D_B: 0.016 G_B: 0.817 cycle_B: 1.619 idt_B: 0.000 perceptual: 10.455 \n",
            "(epoch: 19, iters: 1338, time: 0.924, data: 0.002) D_A: 0.032 G_A: 0.965 cycle_A: 0.903 idt_A: 0.000 D_B: 0.019 G_B: 0.954 cycle_B: 0.502 idt_B: 0.000 perceptual: 8.166 \n",
            "(epoch: 19, iters: 1438, time: 0.512, data: 0.003) D_A: 0.015 G_A: 0.618 cycle_A: 1.419 idt_A: 0.000 D_B: 0.019 G_B: 0.590 cycle_B: 1.270 idt_B: 0.000 perceptual: 8.644 \n",
            "(epoch: 19, iters: 1538, time: 0.510, data: 0.002) D_A: 0.032 G_A: 0.870 cycle_A: 1.939 idt_A: 0.000 D_B: 0.028 G_B: 0.983 cycle_B: 0.331 idt_B: 0.000 perceptual: 12.687 \n",
            "(epoch: 19, iters: 1638, time: 0.514, data: 0.002) D_A: 0.028 G_A: 0.735 cycle_A: 3.152 idt_A: 0.000 D_B: 0.034 G_B: 0.580 cycle_B: 2.941 idt_B: 0.000 perceptual: 16.631 \n",
            "(epoch: 19, iters: 1738, time: 0.754, data: 0.002) D_A: 0.020 G_A: 1.125 cycle_A: 1.737 idt_A: 0.000 D_B: 0.021 G_B: 0.840 cycle_B: 0.515 idt_B: 0.000 perceptual: 8.466 \n",
            "(epoch: 19, iters: 1838, time: 0.515, data: 0.003) D_A: 0.046 G_A: 0.898 cycle_A: 1.522 idt_A: 0.000 D_B: 0.057 G_B: 1.004 cycle_B: 1.505 idt_B: 0.000 perceptual: 10.241 \n",
            "(epoch: 19, iters: 1938, time: 0.506, data: 0.002) D_A: 0.080 G_A: 0.444 cycle_A: 1.887 idt_A: 0.000 D_B: 0.027 G_B: 0.751 cycle_B: 0.937 idt_B: 0.000 perceptual: 9.885 \n",
            "End of epoch 19 / 200 \t Time Taken: 781 sec\n",
            "learning rate 0.0001000 -> 0.0001000\n",
            "(epoch: 20, iters: 61, time: 0.512, data: 0.002) D_A: 0.018 G_A: 0.925 cycle_A: 1.060 idt_A: 0.000 D_B: 0.083 G_B: 0.527 cycle_B: 0.250 idt_B: 0.000 perceptual: 8.673 \n",
            "(epoch: 20, iters: 161, time: 1.249, data: 0.002) D_A: 0.082 G_A: 0.498 cycle_A: 1.801 idt_A: 0.000 D_B: 0.215 G_B: 0.455 cycle_B: 0.645 idt_B: 0.000 perceptual: 8.583 \n",
            "(epoch: 20, iters: 261, time: 0.510, data: 0.002) D_A: 0.090 G_A: 0.733 cycle_A: 1.788 idt_A: 0.000 D_B: 0.103 G_B: 0.409 cycle_B: 0.951 idt_B: 0.000 perceptual: 7.772 \n",
            "(epoch: 20, iters: 361, time: 0.516, data: 0.013) D_A: 0.029 G_A: 0.782 cycle_A: 3.967 idt_A: 0.000 D_B: 0.041 G_B: 0.598 cycle_B: 1.482 idt_B: 0.000 perceptual: 7.870 \n",
            "(epoch: 20, iters: 461, time: 0.516, data: 0.002) D_A: 0.035 G_A: 0.571 cycle_A: 1.471 idt_A: 0.000 D_B: 0.049 G_B: 0.744 cycle_B: 0.473 idt_B: 0.000 perceptual: 6.616 \n",
            "(epoch: 20, iters: 561, time: 0.779, data: 0.002) D_A: 0.047 G_A: 0.665 cycle_A: 1.631 idt_A: 0.000 D_B: 0.023 G_B: 0.800 cycle_B: 0.349 idt_B: 0.000 perceptual: 6.825 \n",
            "(epoch: 20, iters: 661, time: 0.514, data: 0.002) D_A: 0.042 G_A: 0.687 cycle_A: 2.257 idt_A: 0.000 D_B: 0.021 G_B: 0.751 cycle_B: 0.667 idt_B: 0.000 perceptual: 9.367 \n",
            "(epoch: 20, iters: 761, time: 0.516, data: 0.002) D_A: 0.213 G_A: 0.155 cycle_A: 2.091 idt_A: 0.000 D_B: 0.065 G_B: 0.167 cycle_B: 0.896 idt_B: 0.000 perceptual: 11.068 \n",
            "(epoch: 20, iters: 861, time: 0.516, data: 0.002) D_A: 0.359 G_A: 0.072 cycle_A: 1.968 idt_A: 0.000 D_B: 0.059 G_B: 0.659 cycle_B: 0.242 idt_B: 0.000 perceptual: 11.176 \n",
            "(epoch: 20, iters: 961, time: 0.707, data: 0.002) D_A: 0.025 G_A: 0.994 cycle_A: 2.435 idt_A: 0.000 D_B: 0.018 G_B: 1.090 cycle_B: 0.488 idt_B: 0.000 perceptual: 8.037 \n",
            "(epoch: 20, iters: 1061, time: 0.515, data: 0.002) D_A: 0.011 G_A: 0.895 cycle_A: 1.237 idt_A: 0.000 D_B: 0.016 G_B: 0.969 cycle_B: 2.324 idt_B: 0.000 perceptual: 6.266 \n",
            "(epoch: 20, iters: 1161, time: 0.515, data: 0.002) D_A: 0.024 G_A: 0.810 cycle_A: 1.300 idt_A: 0.000 D_B: 0.049 G_B: 0.531 cycle_B: 1.250 idt_B: 0.000 perceptual: 11.108 \n",
            "saving the latest model (epoch 20, total_iters 15000)\n",
            "(epoch: 20, iters: 1261, time: 0.524, data: 0.002) D_A: 0.017 G_A: 1.119 cycle_A: 2.252 idt_A: 0.000 D_B: 0.026 G_B: 0.813 cycle_B: 0.448 idt_B: 0.000 perceptual: 7.404 \n",
            "(epoch: 20, iters: 1361, time: 0.795, data: 0.003) D_A: 0.021 G_A: 1.062 cycle_A: 1.640 idt_A: 0.000 D_B: 0.037 G_B: 0.554 cycle_B: 0.436 idt_B: 0.000 perceptual: 9.377 \n",
            "(epoch: 20, iters: 1461, time: 0.512, data: 0.002) D_A: 0.118 G_A: 0.322 cycle_A: 2.176 idt_A: 0.000 D_B: 0.072 G_B: 1.216 cycle_B: 0.238 idt_B: 0.000 perceptual: 4.996 \n",
            "(epoch: 20, iters: 1561, time: 0.515, data: 0.004) D_A: 0.081 G_A: 0.717 cycle_A: 1.028 idt_A: 0.000 D_B: 0.071 G_B: 0.671 cycle_B: 0.418 idt_B: 0.000 perceptual: 6.635 \n",
            "(epoch: 20, iters: 1661, time: 0.511, data: 0.002) D_A: 0.094 G_A: 0.951 cycle_A: 1.025 idt_A: 0.000 D_B: 0.058 G_B: 0.739 cycle_B: 0.957 idt_B: 0.000 perceptual: 8.249 \n",
            "(epoch: 20, iters: 1761, time: 0.727, data: 0.002) D_A: 0.042 G_A: 0.676 cycle_A: 1.103 idt_A: 0.000 D_B: 0.024 G_B: 1.344 cycle_B: 1.145 idt_B: 0.000 perceptual: 7.113 \n",
            "(epoch: 20, iters: 1861, time: 0.517, data: 0.002) D_A: 0.032 G_A: 0.426 cycle_A: 2.828 idt_A: 0.000 D_B: 0.019 G_B: 0.405 cycle_B: 0.347 idt_B: 0.000 perceptual: 8.709 \n",
            "(epoch: 20, iters: 1961, time: 0.536, data: 0.002) D_A: 0.037 G_A: 0.358 cycle_A: 2.268 idt_A: 0.000 D_B: 0.027 G_B: 1.097 cycle_B: 1.577 idt_B: 0.000 perceptual: 8.947 \n",
            "saving the model at the end of epoch 20, iters 15816\n",
            "End of epoch 20 / 200 \t Time Taken: 785 sec\n",
            "learning rate 0.0001000 -> 0.0001000\n",
            "(epoch: 21, iters: 84, time: 0.514, data: 0.005) D_A: 0.020 G_A: 1.284 cycle_A: 1.457 idt_A: 0.000 D_B: 0.021 G_B: 0.875 cycle_B: 0.913 idt_B: 0.000 perceptual: 10.436 \n",
            "(epoch: 21, iters: 184, time: 1.204, data: 0.002) D_A: 0.166 G_A: 0.636 cycle_A: 0.906 idt_A: 0.000 D_B: 0.035 G_B: 0.515 cycle_B: 3.944 idt_B: 0.000 perceptual: 9.990 \n",
            "(epoch: 21, iters: 284, time: 0.513, data: 0.002) D_A: 0.047 G_A: 0.677 cycle_A: 4.213 idt_A: 0.000 D_B: 0.069 G_B: 0.564 cycle_B: 0.532 idt_B: 0.000 perceptual: 9.141 \n",
            "(epoch: 21, iters: 384, time: 0.525, data: 0.002) D_A: 0.135 G_A: 0.598 cycle_A: 1.910 idt_A: 0.000 D_B: 0.091 G_B: 0.383 cycle_B: 0.612 idt_B: 0.000 perceptual: 8.324 \n",
            "(epoch: 21, iters: 484, time: 0.512, data: 0.002) D_A: 0.086 G_A: 0.644 cycle_A: 1.261 idt_A: 0.000 D_B: 0.089 G_B: 0.419 cycle_B: 0.587 idt_B: 0.000 perceptual: 10.906 \n",
            "(epoch: 21, iters: 584, time: 0.835, data: 0.002) D_A: 0.017 G_A: 0.993 cycle_A: 1.189 idt_A: 0.000 D_B: 0.015 G_B: 0.971 cycle_B: 0.731 idt_B: 0.000 perceptual: 9.015 \n",
            "(epoch: 21, iters: 684, time: 0.516, data: 0.002) D_A: 0.054 G_A: 0.530 cycle_A: 0.916 idt_A: 0.000 D_B: 0.017 G_B: 0.500 cycle_B: 2.392 idt_B: 0.000 perceptual: 9.635 \n",
            "(epoch: 21, iters: 784, time: 0.516, data: 0.002) D_A: 0.018 G_A: 0.914 cycle_A: 1.638 idt_A: 0.000 D_B: 0.071 G_B: 1.146 cycle_B: 0.765 idt_B: 0.000 perceptual: 9.257 \n",
            "(epoch: 21, iters: 884, time: 0.518, data: 0.002) D_A: 0.053 G_A: 0.718 cycle_A: 4.325 idt_A: 0.000 D_B: 0.016 G_B: 0.605 cycle_B: 1.308 idt_B: 0.000 perceptual: 11.708 \n",
            "(epoch: 21, iters: 984, time: 0.684, data: 0.002) D_A: 0.255 G_A: 1.775 cycle_A: 1.469 idt_A: 0.000 D_B: 0.019 G_B: 0.349 cycle_B: 0.531 idt_B: 0.000 perceptual: 11.594 \n",
            "(epoch: 21, iters: 1084, time: 0.516, data: 0.002) D_A: 0.014 G_A: 1.119 cycle_A: 1.048 idt_A: 0.000 D_B: 0.040 G_B: 0.812 cycle_B: 0.766 idt_B: 0.000 perceptual: 8.837 \n",
            "(epoch: 21, iters: 1184, time: 0.513, data: 0.002) D_A: 0.157 G_A: 0.731 cycle_A: 0.907 idt_A: 0.000 D_B: 0.031 G_B: 0.406 cycle_B: 0.287 idt_B: 0.000 perceptual: 7.351 \n",
            "(epoch: 21, iters: 1284, time: 0.515, data: 0.008) D_A: 0.027 G_A: 0.945 cycle_A: 2.069 idt_A: 0.000 D_B: 0.015 G_B: 1.020 cycle_B: 1.286 idt_B: 0.000 perceptual: 12.021 \n",
            "(epoch: 21, iters: 1384, time: 0.784, data: 0.002) D_A: 0.183 G_A: 0.555 cycle_A: 1.653 idt_A: 0.000 D_B: 0.160 G_B: 0.952 cycle_B: 0.781 idt_B: 0.000 perceptual: 6.961 \n",
            "(epoch: 21, iters: 1484, time: 0.516, data: 0.002) D_A: 0.045 G_A: 1.030 cycle_A: 1.628 idt_A: 0.000 D_B: 0.022 G_B: 0.999 cycle_B: 1.201 idt_B: 0.000 perceptual: 7.801 \n",
            "(epoch: 21, iters: 1584, time: 0.514, data: 0.002) D_A: 0.052 G_A: 0.541 cycle_A: 1.414 idt_A: 0.000 D_B: 0.046 G_B: 0.572 cycle_B: 0.333 idt_B: 0.000 perceptual: 8.910 \n",
            "(epoch: 21, iters: 1684, time: 0.517, data: 0.002) D_A: 0.018 G_A: 1.083 cycle_A: 3.901 idt_A: 0.000 D_B: 0.110 G_B: 0.780 cycle_B: 0.855 idt_B: 0.000 perceptual: 9.899 \n",
            "(epoch: 21, iters: 1784, time: 0.752, data: 0.003) D_A: 0.118 G_A: 0.364 cycle_A: 0.978 idt_A: 0.000 D_B: 0.077 G_B: 0.608 cycle_B: 0.372 idt_B: 0.000 perceptual: 6.364 \n",
            "(epoch: 21, iters: 1884, time: 0.520, data: 0.014) D_A: 0.036 G_A: 0.440 cycle_A: 1.081 idt_A: 0.000 D_B: 0.024 G_B: 0.486 cycle_B: 0.475 idt_B: 0.000 perceptual: 8.241 \n",
            "End of epoch 21 / 200 \t Time Taken: 782 sec\n",
            "learning rate 0.0001000 -> 0.0001000\n",
            "(epoch: 22, iters: 7, time: 0.513, data: 0.002) D_A: 0.071 G_A: 0.488 cycle_A: 1.191 idt_A: 0.000 D_B: 0.103 G_B: 0.356 cycle_B: 2.083 idt_B: 0.000 perceptual: 18.129 \n",
            "(epoch: 22, iters: 107, time: 0.513, data: 0.002) D_A: 0.059 G_A: 0.841 cycle_A: 2.182 idt_A: 0.000 D_B: 0.102 G_B: 1.398 cycle_B: 0.340 idt_B: 0.000 perceptual: 9.149 \n",
            "(epoch: 22, iters: 207, time: 1.190, data: 0.002) D_A: 0.024 G_A: 0.760 cycle_A: 1.617 idt_A: 0.000 D_B: 0.027 G_B: 0.758 cycle_B: 0.522 idt_B: 0.000 perceptual: 7.995 \n",
            "(epoch: 22, iters: 307, time: 0.517, data: 0.005) D_A: 0.097 G_A: 0.457 cycle_A: 0.691 idt_A: 0.000 D_B: 0.155 G_B: 0.248 cycle_B: 0.468 idt_B: 0.000 perceptual: 7.678 \n",
            "(epoch: 22, iters: 407, time: 0.514, data: 0.003) D_A: 0.027 G_A: 0.569 cycle_A: 1.162 idt_A: 0.000 D_B: 0.233 G_B: 0.385 cycle_B: 1.572 idt_B: 0.000 perceptual: 9.098 \n",
            "(epoch: 22, iters: 507, time: 0.515, data: 0.013) D_A: 0.033 G_A: 1.042 cycle_A: 1.050 idt_A: 0.000 D_B: 0.016 G_B: 0.773 cycle_B: 0.498 idt_B: 0.000 perceptual: 7.267 \n",
            "(epoch: 22, iters: 607, time: 0.691, data: 0.002) D_A: 0.046 G_A: 0.578 cycle_A: 4.120 idt_A: 0.000 D_B: 0.015 G_B: 1.237 cycle_B: 1.000 idt_B: 0.000 perceptual: 10.952 \n",
            "(epoch: 22, iters: 707, time: 0.515, data: 0.002) D_A: 0.038 G_A: 0.814 cycle_A: 2.404 idt_A: 0.000 D_B: 0.052 G_B: 0.804 cycle_B: 0.560 idt_B: 0.000 perceptual: 7.616 \n",
            "(epoch: 22, iters: 807, time: 0.514, data: 0.002) D_A: 0.135 G_A: 1.065 cycle_A: 3.487 idt_A: 0.000 D_B: 0.240 G_B: 0.999 cycle_B: 0.549 idt_B: 0.000 perceptual: 10.144 \n",
            "(epoch: 22, iters: 907, time: 0.515, data: 0.002) D_A: 0.080 G_A: 0.501 cycle_A: 5.258 idt_A: 0.000 D_B: 0.022 G_B: 0.820 cycle_B: 0.167 idt_B: 0.000 perceptual: 10.473 \n",
            "(epoch: 22, iters: 1007, time: 0.762, data: 0.002) D_A: 0.016 G_A: 0.817 cycle_A: 3.494 idt_A: 0.000 D_B: 0.012 G_B: 0.846 cycle_B: 0.417 idt_B: 0.000 perceptual: 11.067 \n",
            "(epoch: 22, iters: 1107, time: 0.512, data: 0.002) D_A: 0.170 G_A: 0.392 cycle_A: 0.887 idt_A: 0.000 D_B: 0.021 G_B: 0.884 cycle_B: 0.537 idt_B: 0.000 perceptual: 6.363 \n",
            "(epoch: 22, iters: 1207, time: 0.515, data: 0.002) D_A: 0.015 G_A: 1.091 cycle_A: 1.697 idt_A: 0.000 D_B: 0.072 G_B: 0.728 cycle_B: 0.189 idt_B: 0.000 perceptual: 6.636 \n",
            "(epoch: 22, iters: 1307, time: 0.515, data: 0.002) D_A: 0.040 G_A: 0.301 cycle_A: 1.611 idt_A: 0.000 D_B: 0.042 G_B: 0.893 cycle_B: 0.748 idt_B: 0.000 perceptual: 10.643 \n",
            "(epoch: 22, iters: 1407, time: 0.905, data: 0.002) D_A: 0.036 G_A: 0.638 cycle_A: 0.764 idt_A: 0.000 D_B: 0.058 G_B: 0.943 cycle_B: 0.438 idt_B: 0.000 perceptual: 7.129 \n",
            "(epoch: 22, iters: 1507, time: 0.517, data: 0.005) D_A: 0.049 G_A: 0.596 cycle_A: 0.772 idt_A: 0.000 D_B: 0.060 G_B: 0.593 cycle_B: 0.509 idt_B: 0.000 perceptual: 8.325 \n",
            "(epoch: 22, iters: 1607, time: 0.515, data: 0.013) D_A: 0.059 G_A: 0.514 cycle_A: 0.922 idt_A: 0.000 D_B: 0.184 G_B: 1.082 cycle_B: 0.363 idt_B: 0.000 perceptual: 8.402 \n",
            "(epoch: 22, iters: 1707, time: 0.516, data: 0.002) D_A: 0.029 G_A: 0.566 cycle_A: 2.021 idt_A: 0.000 D_B: 0.157 G_B: 0.347 cycle_B: 0.490 idt_B: 0.000 perceptual: 6.406 \n",
            "(epoch: 22, iters: 1807, time: 0.700, data: 0.002) D_A: 0.073 G_A: 1.267 cycle_A: 1.762 idt_A: 0.000 D_B: 0.050 G_B: 0.536 cycle_B: 0.232 idt_B: 0.000 perceptual: 7.154 \n",
            "(epoch: 22, iters: 1907, time: 0.511, data: 0.002) D_A: 0.069 G_A: 0.509 cycle_A: 1.098 idt_A: 0.000 D_B: 0.077 G_B: 0.436 cycle_B: 2.191 idt_B: 0.000 perceptual: 10.430 \n",
            "End of epoch 22 / 200 \t Time Taken: 781 sec\n",
            "learning rate 0.0001000 -> 0.0001000\n",
            "(epoch: 23, iters: 30, time: 0.508, data: 0.002) D_A: 0.143 G_A: 0.275 cycle_A: 1.103 idt_A: 0.000 D_B: 0.077 G_B: 0.448 cycle_B: 0.880 idt_B: 0.000 perceptual: 6.542 \n",
            "(epoch: 23, iters: 130, time: 0.519, data: 0.002) D_A: 0.131 G_A: 0.554 cycle_A: 2.088 idt_A: 0.000 D_B: 0.110 G_B: 0.354 cycle_B: 0.532 idt_B: 0.000 perceptual: 7.715 \n",
            "(epoch: 23, iters: 230, time: 1.767, data: 0.002) D_A: 0.027 G_A: 0.738 cycle_A: 1.442 idt_A: 0.000 D_B: 0.067 G_B: 0.491 cycle_B: 1.120 idt_B: 0.000 perceptual: 10.013 \n",
            "saving the latest model (epoch 23, total_iters 20000)\n",
            "(epoch: 23, iters: 330, time: 0.501, data: 0.002) D_A: 0.051 G_A: 0.936 cycle_A: 1.075 idt_A: 0.000 D_B: 0.039 G_B: 0.717 cycle_B: 0.743 idt_B: 0.000 perceptual: 7.433 \n",
            "(epoch: 23, iters: 430, time: 0.516, data: 0.002) D_A: 0.063 G_A: 0.954 cycle_A: 2.075 idt_A: 0.000 D_B: 0.076 G_B: 0.733 cycle_B: 0.507 idt_B: 0.000 perceptual: 7.432 \n",
            "(epoch: 23, iters: 530, time: 0.515, data: 0.002) D_A: 0.167 G_A: 0.869 cycle_A: 1.878 idt_A: 0.000 D_B: 0.077 G_B: 0.484 cycle_B: 0.257 idt_B: 0.000 perceptual: 7.760 \n",
            "(epoch: 23, iters: 630, time: 0.702, data: 0.003) D_A: 0.110 G_A: 0.951 cycle_A: 1.597 idt_A: 0.000 D_B: 0.078 G_B: 0.253 cycle_B: 0.527 idt_B: 0.000 perceptual: 7.409 \n",
            "(epoch: 23, iters: 730, time: 0.515, data: 0.002) D_A: 0.042 G_A: 0.527 cycle_A: 1.565 idt_A: 0.000 D_B: 0.012 G_B: 1.101 cycle_B: 2.647 idt_B: 0.000 perceptual: 13.477 \n",
            "(epoch: 23, iters: 830, time: 0.512, data: 0.002) D_A: 0.039 G_A: 0.671 cycle_A: 2.078 idt_A: 0.000 D_B: 0.015 G_B: 0.864 cycle_B: 0.471 idt_B: 0.000 perceptual: 7.038 \n",
            "(epoch: 23, iters: 930, time: 0.512, data: 0.002) D_A: 0.016 G_A: 0.879 cycle_A: 1.263 idt_A: 0.000 D_B: 0.060 G_B: 0.605 cycle_B: 1.027 idt_B: 0.000 perceptual: 7.770 \n",
            "(epoch: 23, iters: 1030, time: 0.786, data: 0.003) D_A: 0.019 G_A: 1.187 cycle_A: 1.493 idt_A: 0.000 D_B: 0.052 G_B: 0.700 cycle_B: 0.921 idt_B: 0.000 perceptual: 7.388 \n",
            "(epoch: 23, iters: 1130, time: 0.511, data: 0.002) D_A: 0.043 G_A: 1.301 cycle_A: 0.962 idt_A: 0.000 D_B: 0.020 G_B: 1.209 cycle_B: 0.940 idt_B: 0.000 perceptual: 8.963 \n",
            "(epoch: 23, iters: 1230, time: 0.514, data: 0.002) D_A: 0.019 G_A: 0.927 cycle_A: 2.792 idt_A: 0.000 D_B: 0.065 G_B: 0.202 cycle_B: 1.221 idt_B: 0.000 perceptual: 7.633 \n",
            "(epoch: 23, iters: 1330, time: 0.514, data: 0.002) D_A: 0.139 G_A: 0.314 cycle_A: 2.204 idt_A: 0.000 D_B: 0.117 G_B: 0.312 cycle_B: 0.276 idt_B: 0.000 perceptual: 8.458 \n",
            "(epoch: 23, iters: 1430, time: 0.764, data: 0.002) D_A: 0.014 G_A: 0.920 cycle_A: 1.107 idt_A: 0.000 D_B: 0.092 G_B: 0.445 cycle_B: 0.487 idt_B: 0.000 perceptual: 10.792 \n",
            "(epoch: 23, iters: 1530, time: 0.515, data: 0.002) D_A: 0.094 G_A: 0.381 cycle_A: 0.990 idt_A: 0.000 D_B: 0.101 G_B: 0.938 cycle_B: 1.148 idt_B: 0.000 perceptual: 7.756 \n",
            "(epoch: 23, iters: 1630, time: 0.517, data: 0.002) D_A: 0.048 G_A: 0.615 cycle_A: 1.508 idt_A: 0.000 D_B: 0.046 G_B: 0.420 cycle_B: 0.803 idt_B: 0.000 perceptual: 10.048 \n",
            "(epoch: 23, iters: 1730, time: 0.514, data: 0.014) D_A: 0.042 G_A: 0.757 cycle_A: 1.459 idt_A: 0.000 D_B: 0.110 G_B: 0.363 cycle_B: 1.198 idt_B: 0.000 perceptual: 8.616 \n",
            "(epoch: 23, iters: 1830, time: 0.687, data: 0.002) D_A: 0.035 G_A: 0.732 cycle_A: 2.478 idt_A: 0.000 D_B: 0.038 G_B: 0.720 cycle_B: 0.527 idt_B: 0.000 perceptual: 10.589 \n",
            "(epoch: 23, iters: 1930, time: 0.511, data: 0.002) D_A: 0.079 G_A: 0.467 cycle_A: 1.308 idt_A: 0.000 D_B: 0.035 G_B: 0.718 cycle_B: 0.733 idt_B: 0.000 perceptual: 8.422 \n",
            "End of epoch 23 / 200 \t Time Taken: 784 sec\n",
            "learning rate 0.0001000 -> 0.0001000\n",
            "(epoch: 24, iters: 53, time: 0.512, data: 0.002) D_A: 0.050 G_A: 0.729 cycle_A: 1.452 idt_A: 0.000 D_B: 0.019 G_B: 0.856 cycle_B: 0.224 idt_B: 0.000 perceptual: 5.452 \n",
            "(epoch: 24, iters: 153, time: 0.514, data: 0.002) D_A: 0.045 G_A: 0.805 cycle_A: 1.736 idt_A: 0.000 D_B: 0.018 G_B: 0.428 cycle_B: 0.465 idt_B: 0.000 perceptual: 8.089 \n",
            "(epoch: 24, iters: 253, time: 1.076, data: 0.002) D_A: 0.224 G_A: 0.305 cycle_A: 1.248 idt_A: 0.000 D_B: 0.015 G_B: 0.466 cycle_B: 0.343 idt_B: 0.000 perceptual: 10.090 \n",
            "(epoch: 24, iters: 353, time: 0.514, data: 0.002) D_A: 0.026 G_A: 0.727 cycle_A: 0.839 idt_A: 0.000 D_B: 0.038 G_B: 1.001 cycle_B: 0.468 idt_B: 0.000 perceptual: 5.503 \n",
            "(epoch: 24, iters: 453, time: 0.517, data: 0.002) D_A: 0.159 G_A: 0.555 cycle_A: 3.219 idt_A: 0.000 D_B: 0.224 G_B: 0.136 cycle_B: 0.421 idt_B: 0.000 perceptual: 8.086 \n",
            "(epoch: 24, iters: 553, time: 0.513, data: 0.003) D_A: 0.054 G_A: 0.571 cycle_A: 0.921 idt_A: 0.000 D_B: 0.117 G_B: 0.324 cycle_B: 0.179 idt_B: 0.000 perceptual: 7.382 \n",
            "(epoch: 24, iters: 653, time: 0.750, data: 0.002) D_A: 0.040 G_A: 0.574 cycle_A: 1.876 idt_A: 0.000 D_B: 0.022 G_B: 0.823 cycle_B: 0.485 idt_B: 0.000 perceptual: 7.542 \n",
            "(epoch: 24, iters: 753, time: 0.515, data: 0.002) D_A: 0.125 G_A: 0.692 cycle_A: 1.778 idt_A: 0.000 D_B: 0.017 G_B: 0.424 cycle_B: 0.257 idt_B: 0.000 perceptual: 8.528 \n",
            "(epoch: 24, iters: 853, time: 0.516, data: 0.011) D_A: 0.078 G_A: 0.435 cycle_A: 1.311 idt_A: 0.000 D_B: 0.030 G_B: 0.685 cycle_B: 1.190 idt_B: 0.000 perceptual: 9.105 \n",
            "(epoch: 24, iters: 953, time: 0.517, data: 0.002) D_A: 0.029 G_A: 0.987 cycle_A: 1.313 idt_A: 0.000 D_B: 0.182 G_B: 0.218 cycle_B: 0.321 idt_B: 0.000 perceptual: 8.354 \n",
            "(epoch: 24, iters: 1053, time: 0.755, data: 0.002) D_A: 0.069 G_A: 1.181 cycle_A: 5.279 idt_A: 0.000 D_B: 0.028 G_B: 0.844 cycle_B: 0.894 idt_B: 0.000 perceptual: 9.010 \n",
            "(epoch: 24, iters: 1153, time: 0.506, data: 0.002) D_A: 0.025 G_A: 0.722 cycle_A: 0.906 idt_A: 0.000 D_B: 0.027 G_B: 0.238 cycle_B: 0.396 idt_B: 0.000 perceptual: 5.482 \n",
            "(epoch: 24, iters: 1253, time: 0.515, data: 0.002) D_A: 0.045 G_A: 0.722 cycle_A: 0.959 idt_A: 0.000 D_B: 0.074 G_B: 1.160 cycle_B: 0.737 idt_B: 0.000 perceptual: 9.474 \n",
            "(epoch: 24, iters: 1353, time: 0.514, data: 0.002) D_A: 0.036 G_A: 0.721 cycle_A: 1.453 idt_A: 0.000 D_B: 0.099 G_B: 0.450 cycle_B: 0.226 idt_B: 0.000 perceptual: 7.360 \n",
            "(epoch: 24, iters: 1453, time: 0.690, data: 0.002) D_A: 0.156 G_A: 0.626 cycle_A: 1.349 idt_A: 0.000 D_B: 0.042 G_B: 0.814 cycle_B: 0.727 idt_B: 0.000 perceptual: 6.629 \n",
            "(epoch: 24, iters: 1553, time: 0.512, data: 0.002) D_A: 0.045 G_A: 0.906 cycle_A: 1.748 idt_A: 0.000 D_B: 0.039 G_B: 1.209 cycle_B: 0.873 idt_B: 0.000 perceptual: 8.193 \n",
            "(epoch: 24, iters: 1653, time: 0.514, data: 0.002) D_A: 0.171 G_A: 0.805 cycle_A: 1.086 idt_A: 0.000 D_B: 0.018 G_B: 1.084 cycle_B: 1.171 idt_B: 0.000 perceptual: 7.924 \n",
            "(epoch: 24, iters: 1753, time: 0.515, data: 0.002) D_A: 0.035 G_A: 0.281 cycle_A: 1.886 idt_A: 0.000 D_B: 0.038 G_B: 0.649 cycle_B: 0.950 idt_B: 0.000 perceptual: 13.542 \n",
            "(epoch: 24, iters: 1853, time: 0.726, data: 0.002) D_A: 0.125 G_A: 0.287 cycle_A: 1.223 idt_A: 0.000 D_B: 0.020 G_B: 1.017 cycle_B: 1.086 idt_B: 0.000 perceptual: 9.596 \n",
            "(epoch: 24, iters: 1953, time: 0.514, data: 0.002) D_A: 0.042 G_A: 0.866 cycle_A: 0.984 idt_A: 0.000 D_B: 0.064 G_B: 0.541 cycle_B: 0.317 idt_B: 0.000 perceptual: 7.034 \n",
            "End of epoch 24 / 200 \t Time Taken: 781 sec\n",
            "learning rate 0.0001000 -> 0.0001000\n",
            "(epoch: 25, iters: 76, time: 0.512, data: 0.002) D_A: 0.015 G_A: 1.096 cycle_A: 3.323 idt_A: 0.000 D_B: 0.058 G_B: 1.051 cycle_B: 0.742 idt_B: 0.000 perceptual: 9.484 \n",
            "(epoch: 25, iters: 176, time: 0.515, data: 0.003) D_A: 0.042 G_A: 0.761 cycle_A: 2.515 idt_A: 0.000 D_B: 0.047 G_B: 0.339 cycle_B: 0.726 idt_B: 0.000 perceptual: 5.242 \n",
            "(epoch: 25, iters: 276, time: 1.904, data: 0.002) D_A: 0.062 G_A: 0.850 cycle_A: 2.640 idt_A: 0.000 D_B: 0.033 G_B: 1.247 cycle_B: 0.286 idt_B: 0.000 perceptual: 8.565 \n",
            "(epoch: 25, iters: 376, time: 0.516, data: 0.003) D_A: 0.068 G_A: 0.068 cycle_A: 0.996 idt_A: 0.000 D_B: 0.107 G_B: 0.333 cycle_B: 2.348 idt_B: 0.000 perceptual: 10.780 \n",
            "(epoch: 25, iters: 476, time: 0.516, data: 0.002) D_A: 0.051 G_A: 0.526 cycle_A: 1.903 idt_A: 0.000 D_B: 0.014 G_B: 0.894 cycle_B: 0.633 idt_B: 0.000 perceptual: 7.259 \n",
            "(epoch: 25, iters: 576, time: 0.515, data: 0.002) D_A: 0.085 G_A: 0.618 cycle_A: 1.367 idt_A: 0.000 D_B: 0.050 G_B: 0.893 cycle_B: 0.596 idt_B: 0.000 perceptual: 9.487 \n",
            "(epoch: 25, iters: 676, time: 0.696, data: 0.002) D_A: 0.140 G_A: 0.308 cycle_A: 1.492 idt_A: 0.000 D_B: 0.025 G_B: 0.934 cycle_B: 0.840 idt_B: 0.000 perceptual: 8.925 \n",
            "(epoch: 25, iters: 776, time: 0.514, data: 0.002) D_A: 0.022 G_A: 0.827 cycle_A: 1.794 idt_A: 0.000 D_B: 0.042 G_B: 1.400 cycle_B: 0.417 idt_B: 0.000 perceptual: 6.142 \n",
            "(epoch: 25, iters: 876, time: 0.507, data: 0.003) D_A: 0.055 G_A: 0.455 cycle_A: 1.276 idt_A: 0.000 D_B: 0.036 G_B: 0.786 cycle_B: 0.439 idt_B: 0.000 perceptual: 6.988 \n",
            "(epoch: 25, iters: 976, time: 0.525, data: 0.014) D_A: 0.097 G_A: 0.699 cycle_A: 0.743 idt_A: 0.000 D_B: 0.039 G_B: 1.117 cycle_B: 0.920 idt_B: 0.000 perceptual: 7.167 \n",
            "(epoch: 25, iters: 1076, time: 0.775, data: 0.002) D_A: 0.152 G_A: 0.744 cycle_A: 1.055 idt_A: 0.000 D_B: 0.102 G_B: 0.377 cycle_B: 0.799 idt_B: 0.000 perceptual: 6.786 \n",
            "(epoch: 25, iters: 1176, time: 0.512, data: 0.002) D_A: 0.016 G_A: 0.970 cycle_A: 1.134 idt_A: 0.000 D_B: 0.025 G_B: 1.048 cycle_B: 0.296 idt_B: 0.000 perceptual: 8.773 \n",
            "(epoch: 25, iters: 1276, time: 0.512, data: 0.002) D_A: 0.171 G_A: 1.181 cycle_A: 0.817 idt_A: 0.000 D_B: 0.026 G_B: 0.970 cycle_B: 0.524 idt_B: 0.000 perceptual: 8.995 \n",
            "saving the latest model (epoch 25, total_iters 25000)\n",
            "(epoch: 25, iters: 1376, time: 0.514, data: 0.002) D_A: 0.037 G_A: 0.626 cycle_A: 1.522 idt_A: 0.000 D_B: 0.065 G_B: 0.593 cycle_B: 0.392 idt_B: 0.000 perceptual: 8.904 \n",
            "(epoch: 25, iters: 1476, time: 0.714, data: 0.002) D_A: 0.088 G_A: 0.616 cycle_A: 1.621 idt_A: 0.000 D_B: 0.017 G_B: 0.176 cycle_B: 0.355 idt_B: 0.000 perceptual: 6.631 \n",
            "(epoch: 25, iters: 1576, time: 0.505, data: 0.002) D_A: 0.053 G_A: 0.813 cycle_A: 2.126 idt_A: 0.000 D_B: 0.082 G_B: 0.360 cycle_B: 0.678 idt_B: 0.000 perceptual: 9.071 \n",
            "(epoch: 25, iters: 1676, time: 0.513, data: 0.007) D_A: 0.249 G_A: 0.599 cycle_A: 1.680 idt_A: 0.000 D_B: 0.187 G_B: 0.184 cycle_B: 0.425 idt_B: 0.000 perceptual: 10.172 \n",
            "(epoch: 25, iters: 1776, time: 0.513, data: 0.012) D_A: 0.012 G_A: 0.974 cycle_A: 0.873 idt_A: 0.000 D_B: 0.056 G_B: 0.519 cycle_B: 0.530 idt_B: 0.000 perceptual: 10.195 \n",
            "(epoch: 25, iters: 1876, time: 0.784, data: 0.002) D_A: 0.027 G_A: 0.619 cycle_A: 0.960 idt_A: 0.000 D_B: 0.088 G_B: 0.402 cycle_B: 0.643 idt_B: 0.000 perceptual: 8.889 \n",
            "(epoch: 25, iters: 1976, time: 0.515, data: 0.003) D_A: 0.082 G_A: 0.475 cycle_A: 1.782 idt_A: 0.000 D_B: 0.067 G_B: 0.541 cycle_B: 0.397 idt_B: 0.000 perceptual: 8.148 \n",
            "saving the model at the end of epoch 25, iters 25701\n",
            "End of epoch 25 / 200 \t Time Taken: 785 sec\n",
            "learning rate 0.0001000 -> 0.0001000\n",
            "(epoch: 26, iters: 99, time: 0.513, data: 0.002) D_A: 0.014 G_A: 0.918 cycle_A: 1.183 idt_A: 0.000 D_B: 0.113 G_B: 1.156 cycle_B: 1.694 idt_B: 0.000 perceptual: 8.758 \n",
            "(epoch: 26, iters: 199, time: 0.513, data: 0.002) D_A: 0.018 G_A: 0.809 cycle_A: 2.521 idt_A: 0.000 D_B: 0.063 G_B: 0.742 cycle_B: 0.708 idt_B: 0.000 perceptual: 8.114 \n",
            "(epoch: 26, iters: 299, time: 1.005, data: 0.002) D_A: 0.027 G_A: 0.242 cycle_A: 1.079 idt_A: 0.000 D_B: 0.234 G_B: 0.027 cycle_B: 0.505 idt_B: 0.000 perceptual: 8.581 \n",
            "(epoch: 26, iters: 399, time: 0.515, data: 0.002) D_A: 0.049 G_A: 0.646 cycle_A: 3.545 idt_A: 0.000 D_B: 0.039 G_B: 1.007 cycle_B: 0.466 idt_B: 0.000 perceptual: 7.558 \n",
            "(epoch: 26, iters: 499, time: 0.517, data: 0.002) D_A: 0.080 G_A: 1.248 cycle_A: 2.671 idt_A: 0.000 D_B: 0.014 G_B: 1.140 cycle_B: 0.543 idt_B: 0.000 perceptual: 9.078 \n",
            "(epoch: 26, iters: 599, time: 0.514, data: 0.002) D_A: 0.034 G_A: 0.751 cycle_A: 1.733 idt_A: 0.000 D_B: 0.016 G_B: 0.940 cycle_B: 0.571 idt_B: 0.000 perceptual: 8.401 \n",
            "(epoch: 26, iters: 699, time: 0.801, data: 0.002) D_A: 0.018 G_A: 1.050 cycle_A: 2.783 idt_A: 0.000 D_B: 0.177 G_B: 1.722 cycle_B: 0.349 idt_B: 0.000 perceptual: 8.437 \n",
            "(epoch: 26, iters: 799, time: 0.514, data: 0.002) D_A: 0.078 G_A: 0.417 cycle_A: 1.145 idt_A: 0.000 D_B: 0.023 G_B: 0.882 cycle_B: 0.524 idt_B: 0.000 perceptual: 9.508 \n",
            "(epoch: 26, iters: 899, time: 0.516, data: 0.002) D_A: 0.078 G_A: 1.118 cycle_A: 0.881 idt_A: 0.000 D_B: 0.081 G_B: 0.514 cycle_B: 0.468 idt_B: 0.000 perceptual: 7.368 \n",
            "(epoch: 26, iters: 999, time: 0.514, data: 0.002) D_A: 0.149 G_A: 1.154 cycle_A: 1.142 idt_A: 0.000 D_B: 0.218 G_B: 0.489 cycle_B: 0.176 idt_B: 0.000 perceptual: 6.100 \n",
            "(epoch: 26, iters: 1099, time: 0.839, data: 0.002) D_A: 0.111 G_A: 0.375 cycle_A: 2.612 idt_A: 0.000 D_B: 0.100 G_B: 0.369 cycle_B: 0.524 idt_B: 0.000 perceptual: 7.075 \n",
            "(epoch: 26, iters: 1199, time: 0.517, data: 0.002) D_A: 0.018 G_A: 1.397 cycle_A: 1.320 idt_A: 0.000 D_B: 0.123 G_B: 1.037 cycle_B: 1.190 idt_B: 0.000 perceptual: 7.845 \n",
            "(epoch: 26, iters: 1299, time: 0.515, data: 0.002) D_A: 0.175 G_A: 0.653 cycle_A: 0.982 idt_A: 0.000 D_B: 0.177 G_B: 0.745 cycle_B: 0.440 idt_B: 0.000 perceptual: 8.626 \n",
            "(epoch: 26, iters: 1399, time: 0.515, data: 0.002) D_A: 0.028 G_A: 0.621 cycle_A: 0.767 idt_A: 0.000 D_B: 0.047 G_B: 0.540 cycle_B: 0.206 idt_B: 0.000 perceptual: 7.125 \n",
            "(epoch: 26, iters: 1499, time: 0.699, data: 0.002) D_A: 0.062 G_A: 1.308 cycle_A: 1.720 idt_A: 0.000 D_B: 0.054 G_B: 0.580 cycle_B: 0.418 idt_B: 0.000 perceptual: 8.690 \n",
            "(epoch: 26, iters: 1599, time: 0.516, data: 0.002) D_A: 0.050 G_A: 1.521 cycle_A: 1.412 idt_A: 0.000 D_B: 0.115 G_B: 0.823 cycle_B: 0.716 idt_B: 0.000 perceptual: 7.578 \n",
            "(epoch: 26, iters: 1699, time: 0.540, data: 0.002) D_A: 0.046 G_A: 1.332 cycle_A: 1.565 idt_A: 0.000 D_B: 0.028 G_B: 1.512 cycle_B: 1.113 idt_B: 0.000 perceptual: 8.813 \n",
            "(epoch: 26, iters: 1799, time: 0.510, data: 0.002) D_A: 0.136 G_A: 0.709 cycle_A: 2.102 idt_A: 0.000 D_B: 0.045 G_B: 1.495 cycle_B: 0.372 idt_B: 0.000 perceptual: 8.794 \n",
            "(epoch: 26, iters: 1899, time: 0.710, data: 0.002) D_A: 0.040 G_A: 0.768 cycle_A: 0.909 idt_A: 0.000 D_B: 0.028 G_B: 0.681 cycle_B: 0.540 idt_B: 0.000 perceptual: 5.546 \n",
            "End of epoch 26 / 200 \t Time Taken: 781 sec\n",
            "learning rate 0.0001000 -> 0.0001000\n",
            "(epoch: 27, iters: 22, time: 0.515, data: 0.002) D_A: 0.040 G_A: 0.643 cycle_A: 2.022 idt_A: 0.000 D_B: 0.058 G_B: 0.834 cycle_B: 0.608 idt_B: 0.000 perceptual: 7.989 \n",
            "(epoch: 27, iters: 122, time: 0.513, data: 0.002) D_A: 0.048 G_A: 0.537 cycle_A: 1.848 idt_A: 0.000 D_B: 0.031 G_B: 0.878 cycle_B: 0.684 idt_B: 0.000 perceptual: 6.969 \n",
            "(epoch: 27, iters: 222, time: 0.514, data: 0.002) D_A: 0.083 G_A: 0.322 cycle_A: 1.122 idt_A: 0.000 D_B: 0.050 G_B: 0.555 cycle_B: 0.478 idt_B: 0.000 perceptual: 6.341 \n",
            "(epoch: 27, iters: 322, time: 1.237, data: 0.003) D_A: 0.107 G_A: 1.565 cycle_A: 0.923 idt_A: 0.000 D_B: 0.059 G_B: 0.350 cycle_B: 0.771 idt_B: 0.000 perceptual: 11.894 \n",
            "(epoch: 27, iters: 422, time: 0.516, data: 0.002) D_A: 0.040 G_A: 0.952 cycle_A: 0.957 idt_A: 0.000 D_B: 0.071 G_B: 0.942 cycle_B: 0.948 idt_B: 0.000 perceptual: 7.450 \n",
            "(epoch: 27, iters: 522, time: 0.513, data: 0.015) D_A: 0.020 G_A: 0.552 cycle_A: 0.940 idt_A: 0.000 D_B: 0.071 G_B: 1.276 cycle_B: 1.111 idt_B: 0.000 perceptual: 6.770 \n",
            "(epoch: 27, iters: 622, time: 0.516, data: 0.004) D_A: 0.173 G_A: 0.814 cycle_A: 2.188 idt_A: 0.000 D_B: 0.120 G_B: 0.308 cycle_B: 1.481 idt_B: 0.000 perceptual: 9.074 \n",
            "(epoch: 27, iters: 722, time: 0.700, data: 0.002) D_A: 0.025 G_A: 0.320 cycle_A: 1.329 idt_A: 0.000 D_B: 0.027 G_B: 0.827 cycle_B: 0.327 idt_B: 0.000 perceptual: 8.159 \n",
            "(epoch: 27, iters: 822, time: 0.515, data: 0.002) D_A: 0.037 G_A: 0.201 cycle_A: 0.817 idt_A: 0.000 D_B: 0.067 G_B: 0.764 cycle_B: 0.623 idt_B: 0.000 perceptual: 7.032 \n",
            "(epoch: 27, iters: 922, time: 0.516, data: 0.002) D_A: 0.027 G_A: 0.749 cycle_A: 1.153 idt_A: 0.000 D_B: 0.035 G_B: 1.016 cycle_B: 0.846 idt_B: 0.000 perceptual: 10.940 \n",
            "(epoch: 27, iters: 1022, time: 0.517, data: 0.002) D_A: 0.068 G_A: 0.452 cycle_A: 0.916 idt_A: 0.000 D_B: 0.074 G_B: 0.449 cycle_B: 0.163 idt_B: 0.000 perceptual: 6.895 \n",
            "(epoch: 27, iters: 1122, time: 0.818, data: 0.002) D_A: 0.018 G_A: 1.343 cycle_A: 0.770 idt_A: 0.000 D_B: 0.095 G_B: 0.982 cycle_B: 0.323 idt_B: 0.000 perceptual: 5.655 \n",
            "(epoch: 27, iters: 1222, time: 0.515, data: 0.003) D_A: 0.029 G_A: 1.111 cycle_A: 2.189 idt_A: 0.000 D_B: 0.041 G_B: 0.625 cycle_B: 1.273 idt_B: 0.000 perceptual: 12.439 \n",
            "(epoch: 27, iters: 1322, time: 0.514, data: 0.002) D_A: 0.052 G_A: 0.887 cycle_A: 1.089 idt_A: 0.000 D_B: 0.214 G_B: 0.296 cycle_B: 0.532 idt_B: 0.000 perceptual: 9.886 \n",
            "(epoch: 27, iters: 1422, time: 0.514, data: 0.002) D_A: 0.024 G_A: 0.762 cycle_A: 0.764 idt_A: 0.000 D_B: 0.121 G_B: 0.546 cycle_B: 0.433 idt_B: 0.000 perceptual: 4.883 \n",
            "(epoch: 27, iters: 1522, time: 0.697, data: 0.002) D_A: 0.063 G_A: 1.244 cycle_A: 0.848 idt_A: 0.000 D_B: 0.059 G_B: 0.785 cycle_B: 0.276 idt_B: 0.000 perceptual: 6.671 \n",
            "(epoch: 27, iters: 1622, time: 0.516, data: 0.002) D_A: 0.026 G_A: 0.765 cycle_A: 1.221 idt_A: 0.000 D_B: 0.042 G_B: 0.804 cycle_B: 0.522 idt_B: 0.000 perceptual: 7.599 \n",
            "(epoch: 27, iters: 1722, time: 0.514, data: 0.002) D_A: 0.029 G_A: 0.336 cycle_A: 1.686 idt_A: 0.000 D_B: 0.104 G_B: 0.429 cycle_B: 0.565 idt_B: 0.000 perceptual: 6.590 \n",
            "(epoch: 27, iters: 1822, time: 0.510, data: 0.002) D_A: 0.069 G_A: 0.708 cycle_A: 0.959 idt_A: 0.000 D_B: 0.052 G_B: 1.106 cycle_B: 2.028 idt_B: 0.000 perceptual: 8.955 \n",
            "(epoch: 27, iters: 1922, time: 1.004, data: 0.010) D_A: 0.032 G_A: 0.750 cycle_A: 1.350 idt_A: 0.000 D_B: 0.040 G_B: 1.238 cycle_B: 1.198 idt_B: 0.000 perceptual: 8.927 \n",
            "End of epoch 27 / 200 \t Time Taken: 782 sec\n",
            "learning rate 0.0001000 -> 0.0001000\n",
            "(epoch: 28, iters: 45, time: 0.516, data: 0.002) D_A: 0.014 G_A: 0.961 cycle_A: 0.727 idt_A: 0.000 D_B: 0.046 G_B: 1.240 cycle_B: 0.708 idt_B: 0.000 perceptual: 7.717 \n",
            "(epoch: 28, iters: 145, time: 0.514, data: 0.003) D_A: 0.012 G_A: 1.015 cycle_A: 1.381 idt_A: 0.000 D_B: 0.057 G_B: 0.793 cycle_B: 0.559 idt_B: 0.000 perceptual: 8.460 \n",
            "(epoch: 28, iters: 245, time: 0.515, data: 0.002) D_A: 0.016 G_A: 0.633 cycle_A: 0.873 idt_A: 0.000 D_B: 0.017 G_B: 0.914 cycle_B: 0.534 idt_B: 0.000 perceptual: 6.242 \n",
            "(epoch: 28, iters: 345, time: 1.395, data: 0.002) D_A: 0.030 G_A: 0.662 cycle_A: 3.371 idt_A: 0.000 D_B: 0.041 G_B: 0.423 cycle_B: 0.750 idt_B: 0.000 perceptual: 8.132 \n",
            "saving the latest model (epoch 28, total_iters 30000)\n",
            "(epoch: 28, iters: 445, time: 0.513, data: 0.002) D_A: 0.053 G_A: 0.561 cycle_A: 1.428 idt_A: 0.000 D_B: 0.082 G_B: 0.459 cycle_B: 1.249 idt_B: 0.000 perceptual: 7.715 \n",
            "(epoch: 28, iters: 545, time: 0.516, data: 0.002) D_A: 0.017 G_A: 0.567 cycle_A: 2.386 idt_A: 0.000 D_B: 0.083 G_B: 0.645 cycle_B: 1.823 idt_B: 0.000 perceptual: 11.119 \n",
            "(epoch: 28, iters: 645, time: 0.511, data: 0.004) D_A: 0.111 G_A: 0.391 cycle_A: 1.973 idt_A: 0.000 D_B: 0.021 G_B: 0.460 cycle_B: 0.229 idt_B: 0.000 perceptual: 7.917 \n",
            "(epoch: 28, iters: 745, time: 0.705, data: 0.002) D_A: 0.050 G_A: 0.647 cycle_A: 1.649 idt_A: 0.000 D_B: 0.063 G_B: 0.504 cycle_B: 0.220 idt_B: 0.000 perceptual: 6.436 \n",
            "(epoch: 28, iters: 845, time: 0.518, data: 0.004) D_A: 0.114 G_A: 0.329 cycle_A: 1.052 idt_A: 0.000 D_B: 0.052 G_B: 0.721 cycle_B: 0.262 idt_B: 0.000 perceptual: 10.541 \n",
            "(epoch: 28, iters: 945, time: 0.517, data: 0.003) D_A: 0.013 G_A: 0.538 cycle_A: 1.353 idt_A: 0.000 D_B: 0.014 G_B: 0.977 cycle_B: 0.318 idt_B: 0.000 perceptual: 7.027 \n",
            "(epoch: 28, iters: 1045, time: 0.514, data: 0.002) D_A: 0.022 G_A: 0.801 cycle_A: 2.124 idt_A: 0.000 D_B: 0.032 G_B: 1.334 cycle_B: 0.878 idt_B: 0.000 perceptual: 12.074 \n",
            "(epoch: 28, iters: 1145, time: 0.775, data: 0.002) D_A: 0.158 G_A: 0.696 cycle_A: 1.780 idt_A: 0.000 D_B: 0.089 G_B: 0.899 cycle_B: 0.445 idt_B: 0.000 perceptual: 7.806 \n",
            "(epoch: 28, iters: 1245, time: 0.518, data: 0.002) D_A: 0.028 G_A: 0.817 cycle_A: 1.041 idt_A: 0.000 D_B: 0.041 G_B: 1.011 cycle_B: 1.148 idt_B: 0.000 perceptual: 9.364 \n",
            "(epoch: 28, iters: 1345, time: 0.517, data: 0.002) D_A: 0.037 G_A: 0.695 cycle_A: 1.049 idt_A: 0.000 D_B: 0.044 G_B: 0.642 cycle_B: 0.165 idt_B: 0.000 perceptual: 7.218 \n",
            "(epoch: 28, iters: 1445, time: 0.509, data: 0.002) D_A: 0.018 G_A: 0.766 cycle_A: 2.964 idt_A: 0.000 D_B: 0.028 G_B: 0.860 cycle_B: 0.269 idt_B: 0.000 perceptual: 8.169 \n",
            "(epoch: 28, iters: 1545, time: 0.740, data: 0.002) D_A: 0.127 G_A: 0.547 cycle_A: 1.563 idt_A: 0.000 D_B: 0.194 G_B: 1.116 cycle_B: 0.690 idt_B: 0.000 perceptual: 12.590 \n",
            "(epoch: 28, iters: 1645, time: 0.514, data: 0.002) D_A: 0.021 G_A: 0.568 cycle_A: 1.613 idt_A: 0.000 D_B: 0.018 G_B: 0.655 cycle_B: 1.075 idt_B: 0.000 perceptual: 9.963 \n",
            "(epoch: 28, iters: 1745, time: 0.517, data: 0.002) D_A: 0.023 G_A: 0.777 cycle_A: 4.731 idt_A: 0.000 D_B: 0.012 G_B: 0.814 cycle_B: 0.449 idt_B: 0.000 perceptual: 11.164 \n",
            "(epoch: 28, iters: 1845, time: 0.516, data: 0.002) D_A: 0.034 G_A: 0.690 cycle_A: 0.777 idt_A: 0.000 D_B: 0.050 G_B: 0.795 cycle_B: 0.505 idt_B: 0.000 perceptual: 5.615 \n",
            "(epoch: 28, iters: 1945, time: 0.769, data: 0.002) D_A: 0.021 G_A: 1.197 cycle_A: 0.792 idt_A: 0.000 D_B: 0.065 G_B: 1.502 cycle_B: 0.842 idt_B: 0.000 perceptual: 7.943 \n",
            "End of epoch 28 / 200 \t Time Taken: 785 sec\n",
            "learning rate 0.0001000 -> 0.0001000\n",
            "(epoch: 29, iters: 68, time: 0.516, data: 0.002) D_A: 0.043 G_A: 1.040 cycle_A: 1.260 idt_A: 0.000 D_B: 0.012 G_B: 0.971 cycle_B: 0.404 idt_B: 0.000 perceptual: 9.046 \n",
            "(epoch: 29, iters: 168, time: 0.510, data: 0.018) D_A: 0.138 G_A: 0.570 cycle_A: 1.046 idt_A: 0.000 D_B: 0.074 G_B: 0.431 cycle_B: 0.476 idt_B: 0.000 perceptual: 7.126 \n",
            "(epoch: 29, iters: 268, time: 0.525, data: 0.002) D_A: 0.034 G_A: 0.767 cycle_A: 1.191 idt_A: 0.000 D_B: 0.041 G_B: 0.126 cycle_B: 0.273 idt_B: 0.000 perceptual: 6.813 \n",
            "(epoch: 29, iters: 368, time: 1.187, data: 0.002) D_A: 0.110 G_A: 0.302 cycle_A: 0.959 idt_A: 0.000 D_B: 0.050 G_B: 0.904 cycle_B: 1.381 idt_B: 0.000 perceptual: 15.811 \n",
            "(epoch: 29, iters: 468, time: 0.516, data: 0.002) D_A: 0.026 G_A: 0.762 cycle_A: 1.084 idt_A: 0.000 D_B: 0.045 G_B: 0.593 cycle_B: 0.364 idt_B: 0.000 perceptual: 10.944 \n",
            "(epoch: 29, iters: 568, time: 0.516, data: 0.002) D_A: 0.075 G_A: 1.380 cycle_A: 0.970 idt_A: 0.000 D_B: 0.126 G_B: 0.641 cycle_B: 2.130 idt_B: 0.000 perceptual: 9.204 \n",
            "(epoch: 29, iters: 668, time: 0.513, data: 0.003) D_A: 0.083 G_A: 0.900 cycle_A: 1.010 idt_A: 0.000 D_B: 0.029 G_B: 0.846 cycle_B: 0.381 idt_B: 0.000 perceptual: 7.974 \n",
            "(epoch: 29, iters: 768, time: 0.687, data: 0.002) D_A: 0.082 G_A: 0.530 cycle_A: 1.225 idt_A: 0.000 D_B: 0.084 G_B: 0.927 cycle_B: 0.624 idt_B: 0.000 perceptual: 7.656 \n",
            "(epoch: 29, iters: 868, time: 0.513, data: 0.003) D_A: 0.063 G_A: 0.487 cycle_A: 1.364 idt_A: 0.000 D_B: 0.077 G_B: 0.226 cycle_B: 0.207 idt_B: 0.000 perceptual: 7.867 \n",
            "(epoch: 29, iters: 968, time: 0.518, data: 0.002) D_A: 0.051 G_A: 0.904 cycle_A: 3.082 idt_A: 0.000 D_B: 0.016 G_B: 0.617 cycle_B: 0.194 idt_B: 0.000 perceptual: 17.343 \n",
            "(epoch: 29, iters: 1068, time: 0.515, data: 0.002) D_A: 0.066 G_A: 1.038 cycle_A: 1.745 idt_A: 0.000 D_B: 0.057 G_B: 1.025 cycle_B: 0.983 idt_B: 0.000 perceptual: 12.416 \n",
            "(epoch: 29, iters: 1168, time: 0.749, data: 0.002) D_A: 0.014 G_A: 0.294 cycle_A: 0.802 idt_A: 0.000 D_B: 0.043 G_B: 0.815 cycle_B: 1.013 idt_B: 0.000 perceptual: 9.202 \n",
            "(epoch: 29, iters: 1268, time: 0.516, data: 0.010) D_A: 0.074 G_A: 0.286 cycle_A: 0.850 idt_A: 0.000 D_B: 0.027 G_B: 0.873 cycle_B: 0.323 idt_B: 0.000 perceptual: 8.396 \n",
            "(epoch: 29, iters: 1368, time: 0.516, data: 0.002) D_A: 0.030 G_A: 0.755 cycle_A: 2.172 idt_A: 0.000 D_B: 0.067 G_B: 1.111 cycle_B: 0.690 idt_B: 0.000 perceptual: 6.372 \n",
            "(epoch: 29, iters: 1468, time: 0.512, data: 0.002) D_A: 0.018 G_A: 0.827 cycle_A: 0.826 idt_A: 0.000 D_B: 0.058 G_B: 1.343 cycle_B: 0.543 idt_B: 0.000 perceptual: 6.272 \n",
            "(epoch: 29, iters: 1568, time: 0.910, data: 0.003) D_A: 0.088 G_A: 0.609 cycle_A: 1.145 idt_A: 0.000 D_B: 0.043 G_B: 0.879 cycle_B: 1.166 idt_B: 0.000 perceptual: 8.524 \n",
            "(epoch: 29, iters: 1668, time: 0.517, data: 0.002) D_A: 0.056 G_A: 1.139 cycle_A: 1.241 idt_A: 0.000 D_B: 0.076 G_B: 0.491 cycle_B: 0.634 idt_B: 0.000 perceptual: 7.037 \n",
            "(epoch: 29, iters: 1768, time: 0.516, data: 0.014) D_A: 0.227 G_A: 1.014 cycle_A: 1.156 idt_A: 0.000 D_B: 0.038 G_B: 0.466 cycle_B: 1.126 idt_B: 0.000 perceptual: 6.173 \n",
            "(epoch: 29, iters: 1868, time: 0.513, data: 0.002) D_A: 0.042 G_A: 0.636 cycle_A: 0.789 idt_A: 0.000 D_B: 0.032 G_B: 0.851 cycle_B: 0.342 idt_B: 0.000 perceptual: 6.942 \n",
            "(epoch: 29, iters: 1968, time: 0.699, data: 0.002) D_A: 0.022 G_A: 0.930 cycle_A: 1.193 idt_A: 0.000 D_B: 0.066 G_B: 0.595 cycle_B: 0.260 idt_B: 0.000 perceptual: 7.204 \n",
            "End of epoch 29 / 200 \t Time Taken: 782 sec\n",
            "learning rate 0.0001000 -> 0.0001000\n",
            "(epoch: 30, iters: 91, time: 0.510, data: 0.003) D_A: 0.044 G_A: 0.796 cycle_A: 1.230 idt_A: 0.000 D_B: 0.036 G_B: 0.993 cycle_B: 0.434 idt_B: 0.000 perceptual: 8.780 \n",
            "(epoch: 30, iters: 191, time: 0.514, data: 0.002) D_A: 0.023 G_A: 1.094 cycle_A: 0.985 idt_A: 0.000 D_B: 0.071 G_B: 0.977 cycle_B: 0.289 idt_B: 0.000 perceptual: 6.798 \n",
            "(epoch: 30, iters: 291, time: 0.516, data: 0.002) D_A: 0.052 G_A: 0.913 cycle_A: 1.419 idt_A: 0.000 D_B: 0.052 G_B: 0.655 cycle_B: 0.394 idt_B: 0.000 perceptual: 5.278 \n",
            "(epoch: 30, iters: 391, time: 1.221, data: 0.002) D_A: 0.035 G_A: 0.588 cycle_A: 0.890 idt_A: 0.000 D_B: 0.016 G_B: 0.963 cycle_B: 0.433 idt_B: 0.000 perceptual: 7.129 \n",
            "(epoch: 30, iters: 491, time: 0.514, data: 0.011) D_A: 0.033 G_A: 0.679 cycle_A: 1.059 idt_A: 0.000 D_B: 0.026 G_B: 0.973 cycle_B: 0.908 idt_B: 0.000 perceptual: 9.151 \n",
            "(epoch: 30, iters: 591, time: 0.516, data: 0.002) D_A: 0.020 G_A: 0.915 cycle_A: 2.144 idt_A: 0.000 D_B: 0.014 G_B: 0.860 cycle_B: 0.415 idt_B: 0.000 perceptual: 8.841 \n",
            "(epoch: 30, iters: 691, time: 0.518, data: 0.002) D_A: 0.023 G_A: 0.624 cycle_A: 0.848 idt_A: 0.000 D_B: 0.093 G_B: 0.996 cycle_B: 0.175 idt_B: 0.000 perceptual: 5.899 \n",
            "(epoch: 30, iters: 791, time: 0.691, data: 0.002) D_A: 0.149 G_A: 0.488 cycle_A: 1.110 idt_A: 0.000 D_B: 0.079 G_B: 0.915 cycle_B: 0.328 idt_B: 0.000 perceptual: 9.304 \n",
            "(epoch: 30, iters: 891, time: 0.508, data: 0.002) D_A: 0.031 G_A: 0.676 cycle_A: 0.912 idt_A: 0.000 D_B: 0.051 G_B: 0.693 cycle_B: 0.254 idt_B: 0.000 perceptual: 7.055 \n",
            "(epoch: 30, iters: 991, time: 0.508, data: 0.004) D_A: 0.011 G_A: 0.994 cycle_A: 1.133 idt_A: 0.000 D_B: 0.024 G_B: 1.094 cycle_B: 1.023 idt_B: 0.000 perceptual: 5.063 \n",
            "(epoch: 30, iters: 1091, time: 0.517, data: 0.003) D_A: 0.021 G_A: 0.882 cycle_A: 2.349 idt_A: 0.000 D_B: 0.023 G_B: 0.804 cycle_B: 0.376 idt_B: 0.000 perceptual: 8.726 \n",
            "(epoch: 30, iters: 1191, time: 0.703, data: 0.002) D_A: 0.026 G_A: 0.737 cycle_A: 0.840 idt_A: 0.000 D_B: 0.104 G_B: 0.436 cycle_B: 0.209 idt_B: 0.000 perceptual: 6.098 \n",
            "(epoch: 30, iters: 1291, time: 0.513, data: 0.002) D_A: 0.406 G_A: 1.306 cycle_A: 1.854 idt_A: 0.000 D_B: 0.018 G_B: 0.811 cycle_B: 0.601 idt_B: 0.000 perceptual: 8.639 \n",
            "(epoch: 30, iters: 1391, time: 0.516, data: 0.002) D_A: 0.116 G_A: 0.575 cycle_A: 0.879 idt_A: 0.000 D_B: 0.168 G_B: 0.560 cycle_B: 0.830 idt_B: 0.000 perceptual: 6.084 \n",
            "saving the latest model (epoch 30, total_iters 35000)\n",
            "(epoch: 30, iters: 1491, time: 0.513, data: 0.002) D_A: 0.154 G_A: 0.504 cycle_A: 1.447 idt_A: 0.000 D_B: 0.022 G_B: 0.780 cycle_B: 1.012 idt_B: 0.000 perceptual: 8.763 \n",
            "(epoch: 30, iters: 1591, time: 0.793, data: 0.002) D_A: 0.108 G_A: 0.630 cycle_A: 2.585 idt_A: 0.000 D_B: 0.085 G_B: 0.792 cycle_B: 0.517 idt_B: 0.000 perceptual: 7.376 \n",
            "(epoch: 30, iters: 1691, time: 0.508, data: 0.002) D_A: 0.037 G_A: 0.609 cycle_A: 0.952 idt_A: 0.000 D_B: 0.021 G_B: 0.798 cycle_B: 1.048 idt_B: 0.000 perceptual: 8.598 \n",
            "(epoch: 30, iters: 1791, time: 0.527, data: 0.011) D_A: 0.062 G_A: 0.990 cycle_A: 1.194 idt_A: 0.000 D_B: 0.023 G_B: 0.949 cycle_B: 0.774 idt_B: 0.000 perceptual: 9.134 \n",
            "(epoch: 30, iters: 1891, time: 0.515, data: 0.007) D_A: 0.018 G_A: 1.313 cycle_A: 1.159 idt_A: 0.000 D_B: 0.069 G_B: 0.534 cycle_B: 0.516 idt_B: 0.000 perceptual: 7.079 \n",
            "saving the model at the end of epoch 30, iters 35586\n",
            "End of epoch 30 / 200 \t Time Taken: 785 sec\n",
            "learning rate 0.0001000 -> 0.0001000\n",
            "(epoch: 31, iters: 14, time: 1.294, data: 0.002) D_A: 0.031 G_A: 0.689 cycle_A: 1.632 idt_A: 0.000 D_B: 0.014 G_B: 0.635 cycle_B: 0.493 idt_B: 0.000 perceptual: 9.357 \n",
            "(epoch: 31, iters: 114, time: 0.514, data: 0.002) D_A: 0.060 G_A: 0.317 cycle_A: 1.372 idt_A: 0.000 D_B: 0.069 G_B: 1.092 cycle_B: 0.371 idt_B: 0.000 perceptual: 9.638 \n",
            "(epoch: 31, iters: 214, time: 0.509, data: 0.002) D_A: 0.039 G_A: 0.632 cycle_A: 2.180 idt_A: 0.000 D_B: 0.028 G_B: 0.926 cycle_B: 1.280 idt_B: 0.000 perceptual: 7.087 \n",
            "(epoch: 31, iters: 314, time: 0.514, data: 0.002) D_A: 0.106 G_A: 1.082 cycle_A: 1.439 idt_A: 0.000 D_B: 0.078 G_B: 0.644 cycle_B: 0.870 idt_B: 0.000 perceptual: 6.312 \n",
            "(epoch: 31, iters: 414, time: 1.160, data: 0.002) D_A: 0.047 G_A: 0.587 cycle_A: 1.039 idt_A: 0.000 D_B: 0.021 G_B: 0.772 cycle_B: 0.548 idt_B: 0.000 perceptual: 10.105 \n",
            "(epoch: 31, iters: 514, time: 0.522, data: 0.002) D_A: 0.037 G_A: 0.601 cycle_A: 0.688 idt_A: 0.000 D_B: 0.042 G_B: 1.052 cycle_B: 0.289 idt_B: 0.000 perceptual: 5.193 \n",
            "(epoch: 31, iters: 614, time: 0.511, data: 0.004) D_A: 0.052 G_A: 0.557 cycle_A: 0.984 idt_A: 0.000 D_B: 0.024 G_B: 0.833 cycle_B: 0.393 idt_B: 0.000 perceptual: 7.151 \n",
            "(epoch: 31, iters: 714, time: 0.514, data: 0.002) D_A: 0.025 G_A: 0.739 cycle_A: 1.155 idt_A: 0.000 D_B: 0.061 G_B: 0.497 cycle_B: 0.232 idt_B: 0.000 perceptual: 5.616 \n",
            "(epoch: 31, iters: 814, time: 0.790, data: 0.002) D_A: 0.052 G_A: 1.026 cycle_A: 1.841 idt_A: 0.000 D_B: 0.025 G_B: 0.577 cycle_B: 1.773 idt_B: 0.000 perceptual: 10.645 \n",
            "(epoch: 31, iters: 914, time: 0.517, data: 0.002) D_A: 0.015 G_A: 0.477 cycle_A: 0.941 idt_A: 0.000 D_B: 0.050 G_B: 0.667 cycle_B: 0.313 idt_B: 0.000 perceptual: 8.613 \n",
            "(epoch: 31, iters: 1014, time: 0.512, data: 0.002) D_A: 0.031 G_A: 0.653 cycle_A: 1.138 idt_A: 0.000 D_B: 0.073 G_B: 1.207 cycle_B: 1.280 idt_B: 0.000 perceptual: 8.166 \n",
            "(epoch: 31, iters: 1114, time: 0.512, data: 0.003) D_A: 0.095 G_A: 0.392 cycle_A: 1.227 idt_A: 0.000 D_B: 0.027 G_B: 0.719 cycle_B: 1.181 idt_B: 0.000 perceptual: 6.339 \n",
            "(epoch: 31, iters: 1214, time: 0.952, data: 0.002) D_A: 0.019 G_A: 0.521 cycle_A: 1.068 idt_A: 0.000 D_B: 0.044 G_B: 1.014 cycle_B: 0.921 idt_B: 0.000 perceptual: 6.908 \n",
            "(epoch: 31, iters: 1314, time: 0.514, data: 0.003) D_A: 0.042 G_A: 0.609 cycle_A: 1.649 idt_A: 0.000 D_B: 0.043 G_B: 0.393 cycle_B: 0.977 idt_B: 0.000 perceptual: 8.005 \n",
            "(epoch: 31, iters: 1414, time: 0.513, data: 0.002) D_A: 0.120 G_A: 0.776 cycle_A: 0.721 idt_A: 0.000 D_B: 0.027 G_B: 0.742 cycle_B: 0.166 idt_B: 0.000 perceptual: 6.353 \n",
            "(epoch: 31, iters: 1514, time: 0.516, data: 0.002) D_A: 0.067 G_A: 0.493 cycle_A: 1.250 idt_A: 0.000 D_B: 0.027 G_B: 0.987 cycle_B: 0.353 idt_B: 0.000 perceptual: 8.449 \n",
            "(epoch: 31, iters: 1614, time: 0.693, data: 0.002) D_A: 0.046 G_A: 1.147 cycle_A: 2.504 idt_A: 0.000 D_B: 0.068 G_B: 0.778 cycle_B: 0.691 idt_B: 0.000 perceptual: 7.290 \n",
            "(epoch: 31, iters: 1714, time: 0.518, data: 0.002) D_A: 0.019 G_A: 0.495 cycle_A: 0.832 idt_A: 0.000 D_B: 0.053 G_B: 0.831 cycle_B: 0.641 idt_B: 0.000 perceptual: 8.522 \n",
            "(epoch: 31, iters: 1814, time: 0.514, data: 0.002) D_A: 0.050 G_A: 0.584 cycle_A: 0.837 idt_A: 0.000 D_B: 0.141 G_B: 0.742 cycle_B: 0.235 idt_B: 0.000 perceptual: 7.347 \n",
            "(epoch: 31, iters: 1914, time: 0.514, data: 0.002) D_A: 0.047 G_A: 0.409 cycle_A: 1.229 idt_A: 0.000 D_B: 0.062 G_B: 1.091 cycle_B: 0.258 idt_B: 0.000 perceptual: 9.195 \n",
            "End of epoch 31 / 200 \t Time Taken: 783 sec\n",
            "learning rate 0.0001000 -> 0.0001000\n",
            "(epoch: 32, iters: 37, time: 1.066, data: 0.002) D_A: 0.013 G_A: 0.918 cycle_A: 0.689 idt_A: 0.000 D_B: 0.046 G_B: 1.341 cycle_B: 0.376 idt_B: 0.000 perceptual: 5.930 \n",
            "(epoch: 32, iters: 137, time: 0.516, data: 0.002) D_A: 0.053 G_A: 0.771 cycle_A: 1.177 idt_A: 0.000 D_B: 0.040 G_B: 0.831 cycle_B: 0.203 idt_B: 0.000 perceptual: 7.733 \n"
          ]
        }
      ]
    }
  ]
}